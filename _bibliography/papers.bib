---
---


@ARTICLE{7038220,
  bibtex_show={true},
  abbr={IEEE TVT},
  author={Wang, Fei and Xu, Yongjun and Zhang, Hanwen and Zhang, Yujun and Zhu, Liehuang},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={2FLIP: A Two-Factor Lightweight Privacy-Preserving Authentication Scheme for VANET}, 
  year={2016},
  month=feb,
  volume={65},
  number={2},
  pages={896-911},
  keywords={Vehicles;Privacy;Vehicular ad hoc networks;Authentication;Telematics;Biology;Privacy;vehicular ad hoc network;two factor authentication;conditional traceability;strong non-repudiation;Conditional traceability;privacy;strong nonrepudiation;two-factor authentication;vehicular ad-hoc network (VANET)},
  doi={10.1109/TVT.2015.2402166},
  google_scholar_id={d1gkVwhDpl0C},
  selected={true}
  }

  @article{Wu_Xu_Wang_Wang_Xu_2017, 
    bibtex_show={true},
    abbr={Navigation},
    title={Mapping Global Shipping Density from AIS Data}, 
    volume={70}, 
    DOI={10.1017/S0373463316000345}, 
    number={1}, 
    journal={Journal of Navigation}, 
    author={Wu, Lin and Xu, Yongjun and Wang, Qi and Wang, Fei and Xu, Zhiwei}, 
    year={2017}, 
    pages={67-81},
    google_scholar_id={ufrVoPGSRksC},
    selected={true}
  } 

@article{XU2021100179,
  bibtex_show={true},
  abbr={Innovation},
  title = {Artificial intelligence: A powerful paradigm for scientific research},
  journal = {The Innovation},
  volume = {2},
  number = {4},
  pages = {100179},
  year = {2021},
  month = nov,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2021.100179},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675821001041},
  author = {Yongjun Xu and Xin Liu and Xin Cao and Changping Huang and Enke Liu and Sen Qian and Xingchen Liu and Yanjun Wu and Fengliang Dong and Cheng-Wei Qiu and Junjun Qiu and Keqin Hua and Wentao Su and Jian Wu and Huiyu Xu and Yong Han and Chenguang Fu and Zhigang Yin and Miao Liu and Ronald Roepman and Sabine Dietmann and Marko Virta and Fredrick Kengara and Ze Zhang and Lifu Zhang and Taolan Zhao and Ji Dai and Jialiang Yang and Liang Lan and Ming Luo and Zhaofeng Liu and Tao An and Bin Zhang and Xiao He and Shan Cong and Xiaohong Liu and Wei Zhang and James P. Lewis and James M. Tiedje and Qi Wang* and Zhulin An* and Fei Wang* and Libo Zhang* and Tao Huang* and Chuan Lu* and Zhipeng Cai* and Fang Wang* and Jiabao Zhang*},
  keywords = {artificial intelligence, machine learning, deep learning, information science, mathematics, medical science, materials science, geoscience, life science, physics, chemistry},
  abstract = {Artificial intelligence (AI) coupled with promising machine learning (ML) techniques well known from computer science is broadly affecting many aspects of various fields including science and technology, industry, and even our day-to-day life. The ML techniques have been developed to analyze high-throughput data with a view to obtaining useful insights, categorizing, predicting, and making evidence-based decisions in novel ways, which will promote the growth of novel applications and fuel the sustainable booming of AI. This paper undertakes a comprehensive survey on the development and application of AI in different aspects of fundamental sciences, including information science, mathematics, medical science, materials science, geoscience, life science, physics, and chemistry. The challenges that each discipline of science meets, and the potentials of AI techniques to handle these challenges, are discussed in detail. Moreover, we shed light on new research trends entailing the integration of AI into each scientific discipline. The aim of this paper is to provide a broad research guideline on fundamental sciences with potential infusion of AI, to help motivate researchers to deeply understand the state-of-the-art applications of AI-based fundamental sciences, and thereby to help promote the continuous development of these fundamental sciences.},
  google_scholar_id={8k81kl-MbHgC},
  selected={true},
  award={Fei Wang receveid the **Best Paper Award** 2024 *for the contribution to a comprehensive review of AI for Science*},
  award_name={Best Paper Award}
}

@InProceedings{10.1007/978-3-031-00126-0_33,
  bibtex_show={true},
  abbr={DASFAA},
  author={Sun, Tao and Wang, Fei and Zhang, Zhao and Wu, Lin and Xu, Yongjun},
  title={Human Mobility Identification by Deep Behavior Relevant Location Representation},
  booktitle={Database Systems for Advanced Applications},
  year={2022},
  month=apr,
  publisher={Springer International Publishing},
  address={Cham},
  pages={439--454},
  abstract={This paper focuses on Trajectory User Link (TUL), which aims at identifying user identities through exploiting their mobility patterns. Existing TUL approaches are based on location representation, a way to learn location associations by embedding vectors that can indicate the level of semantic similarity between the locations. However, existing methods for location representation don't consider the semantic diversity of locations, which will lead to a misunderstanding of the semantic information of trajectory when linking anonymous trajectories to candidate users. To solve this problem, in this paper, we propose Deep Behavior Relevant Location representation (DBRLr) to map the polysemous locations into distinct vectors, from the perspective of users' behavior to reflect the semantic polysemy of locations. To learn this representation, we build a Location Prediction-based Movement Model (LP-based MM), which learns user behavior representation at each visited location from a large history trajectory corpora. LP-based MM considers both Continuity and Cyclicity characteristics of user's movement. We employ the combination of the intermediate layer representation in LP-based MM as DBRLr. An effective recurrent neural network is used to link anonymous trajectories with candidate users. Experiments are conducted on two real-world datasets, and the result shows that our method performs beyond existing methods.},
  isbn={978-3-031-00126-0},
  google_scholar_id={KlAtU1dfN6UC},
  selected={true},
  award={Fei Wang receveid the **Best Student Paper Award** 2022 *for the contribution to method of Deep Behavior Relevant Location Representation*},
  award_name={Best Student Paper Award}
}


@article{10.14778/3551793.3551827,
  bibtex_show={true},
  abbr={VLDB},
  author = {Shao, Zezhi and Zhang, Zhao and Wei*, Wei and Wang*, Fei and Xu, Yongjun and Cao, Xin and Jensen, Christian S.},
  title = {Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting},
  year = {2022},
  publisher = {VLDB Endowment},
  volume = {15},
  number = {11},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3551793.3551827},
  doi = {10.14778/3551793.3551827},
  abstract = {We all depend on mobility, and vehicular transportation affects the daily lives of most of us. Thus, the ability to forecast the state of traffic in a road network is an important functionality and a challenging task. Traffic data is often obtained from sensors deployed in a road network. Recent proposals on spatial-temporal graph neural networks have achieved great progress at modeling complex spatial-temporal correlations in traffic data, by modeling traffic data as a diffusion process. However, intuitively, traffic data encompasses two different kinds of hidden time series signals, namely the diffusion signals and inherent signals. Unfortunately, nearly all previous works coarsely consider traffic signals entirely as the outcome of the diffusion, while neglecting the inherent signals, which impacts model performance negatively. To improve modeling performance, we propose a novel Decoupled Spatial-Temporal Framework (DSTF) that separates the diffusion and inherent traffic information in a data-driven manner, which encompasses a unique estimation gate and a residual decomposition mechanism. The separated signals can be handled subsequently by the diffusion and inherent modules separately. Further, we propose an instantiation of DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network (D2STGNN), that captures spatial-temporal correlations and also features a dynamic graph learning module that targets the learning of the dynamic characteristics of traffic networks. Extensive experiments with four real-world traffic datasets demonstrate that the framework is capable of advancing the state-of-the-art.},
  journal = {Proc. VLDB Endow.},
  month = jul,
  pages = {2733-2746},
  numpages = {14},
  google_scholar_id={D_sINldO8mEC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/D2STGNN},
  award={**The 3rd-Most Cited paper in VLDB 2022** 2022 *3/357*},
  award_name={The 3rd-Most Cited paper in VLDB 2022}
}

@inproceedings{10.1145/3534678.3539396,
  bibtex_show={true},
  abbr={KDD},
  author = {Shao, Zezhi and Zhang, Zhao and Wang*, Fei and Xu, Yongjun},
  title = {Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting},
  year = {2022},
  month = aug,
  isbn = {9781450393850},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3534678.3539396},
  doi = {10.1145/3534678.3539396},
  abstract = {Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns.},
  booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages = {1567-1577},
  numpages = {11},
  keywords = {multivariate time series forecasting, pre-training model, spatial-temporal graph neural network},
  location = {Washington DC, USA},
  series = {KDD '22},
  google_scholar_id={HE397vMXCloC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/STEP},
  award={**The 3rd-Most Cited paper in KDD 2022** 2022 *3/254*},
  award_name={The 3rd-Most Cited paper in KDD 2022}
}

@inproceedings{10.1145/3511808.3557702,
  bibtex_show={true},
  abbr={CIKM},
  author = {Shao, Zezhi and Zhang, Zhao and Wang*, Fei and Wei, Wei and Xu, Yongjun},
  title = {Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting},
  year = {2022},
  month = oct,
  isbn = {9781450392365},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3511808.3557702},
  doi = {10.1145/3511808.3557702},
  abstract = {Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods due to their state-of-the-art performance. However, recent works are becoming more sophisticated with limited performance improvements. This phenomenon motivates us to explore the critical factors of MTS forecasting and design a model that is as powerful as STGNNs, but more concise and efficient. In this paper, we identify the indistinguishability of samples in both spatial and temporal dimensions as a key bottleneck, and propose a simple yet effective baseline for MTS forecasting by attaching <u>S</u>patial and <u>T</u>emporal <u>ID</u>entity information (STID), which achieves the best performance and efficiency simultaneously based on simple Multi-Layer Perceptrons (MLPs). These results suggest that we can design efficient and effective models as long as they solve the indistinguishability of samples, without being limited to STGNNs.},
  booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages = {4454-4458},
  numpages = {5},
  keywords = {spatial-temporal graph neural network, multivariate time series forecasting, baseline},
  location = {Atlanta, GA, USA},
  series = {CIKM '22},
  google_scholar_id={4TOpqqG69KYC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/STID},
  award={**The Most Cited paper in CIKM 2022** 2022 *1/561*},
  award_name={The Most Cited paper in CIKM 2022}
}

@inproceedings{10.1145/3583780.3614851,
  bibtex_show={true},
  abbr={CIKM},
  author = {Yu, Chengqing and Wang*, Fei and Shao, Zezhi and Sun, Tao and Wu, Lin and Xu, Yongjun},
  title = {DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction},
  year = {2023},
  month = oct,
  isbn = {9798400701245},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3583780.3614851},
  doi = {10.1145/3583780.3614851},
  abstract = {Multivariate time series long-term prediction, which aims to predict the change of data in a long time, can provide references for decision-making. Although transformer-based models have made progress in this field, they usually do not make full use of three features of multivariate time series: global information, local information, and variables correlation. To effectively mine the above three features and establish a high-precision prediction model, we propose a double sampling transformer (DSformer), which consists of the double sampling (DS) block and the temporal variable attention (TVA) block. Firstly, the DS block employs down sampling and piecewise sampling to transform the original series into feature vectors that focus on global information and local information respectively. Then, TVA block uses temporal attention and variable attention to mine these feature vectors from different dimensions and extract key information. Finally, based on a parallel structure, DSformer uses multiple TVA blocks to mine and integrate different features obtained from DS blocks respectively. The integrated feature information is passed to the generative decoder based on a multi-layer perceptron to realize multivariate time series long-term prediction. Experimental results on nine real-world datasets show that DSformer can outperform eight existing baselines.},
  booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages = {3062-3072},
  numpages = {11},
  keywords = {double sampling transformer, multivariate time series long-term prediction, temporal variable attention block},
  location = {Birmingham, United Kingdom},
  series = {CIKM '23},
  google_scholar_id={L8Ckcad2t8MC},
  selected={true},
  code={https://github.com/GestaltCogTeam/DSformer},
  award={**The 2nd-Cited paper in CIKM 2023** 2023 *2/676*},
  award_name={The 2nd-Cited paper in CIKM 2023}
}


@inproceedings{10.1145/3503161.3548092,
  bibtex_show={true},
  abbr={ACM MM},
  author = {Qian, Tangwen and Xu, Yongjun and Zhang, Zhao and Wang, Fei},
  title = {Trajectory Prediction from Hierarchical Perspective},
  year = {2022},
  month=oct,
  isbn = {9781450392037},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3503161.3548092},
  doi = {10.1145/3503161.3548092},
  abstract = {Predicting the future trajectories of multiple agents is essential for various applications in real life, such as surveillance systems, autonomous driving and social robots. The trajectory prediction task is influenced by many factors, including the individual historical trajectory, interactions between agents and fuzzy nature of an agent's motion. While existing methods have made great progress on the topic of trajectory prediction, they treat all the information uniformly, which limits the sufficiency of using information. To this end, in this paper, we propose to regard all the information in a two-level hierarchical view. Particularly, the first-level view is the inter-trajectory view. In this level, we observe that the difficulty to predict different trajectory samples is different. We define trajectory difficulty and train the proposed model in an "easy-to-hard'' schema. The second-level view is the intra-trajectory level. We find the influencing factors for a particular trajectory can be divided into two parts. The first part is global features, which keep stable within a trajectory, i.e., the expected destination. The second part is local features, which change over time, i.e., the current position. We believe that the two types of information should be handled in different ways. The hierarchical view is beneficial to take full advantage of the information in a fine-grained way. Experimental results validate the effectiveness of the proposed model.},
  booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
  pages = {6822-6830},
  numpages = {9},
  keywords = {hierarchical perspective, spatial-temporal modeling, trajectory prediction},
  location = {Lisboa, Portugal},
  series = {MM '22},
  google_scholar_id={M3ejUd6NZC8C},
  selected={false}
}


@ARTICLE{9961953,
  bibtex_show={true},
  abbr={TKDE},
  author={Shao, Zezhi and Xu, Yongjun and Wei, Wei and Wang, Fei and Zhang, Zhao and Zhu, Feida},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Heterogeneous Graph Neural Network With Multi-View Representation Learning}, 
  year={2023},
  month=nov,
  volume={35},
  number={11},
  pages={11476-11488},
  keywords={Semantics;Mercury (metals);Graph neural networks;Aggregates;Task analysis;Representation learning;Adaptation models;Heterogeneous graphs;graph neural networks;graph embedding},
  doi={10.1109/TKDE.2022.3224193},
  google_scholar_id={hqOjcs7Dif8C},
  selected={false}
  }

@inproceedings{10.1145/3583780.3615253,
  bibtex_show={true},
  abbr={CIKM},
  author = {Wang, Yuan and Shao, Zezhi and Sun, Tao and Yu, Chengqing and Xu, Yongjun and Wang*, Fei},
  title = {Clustering-property Matters: A Cluster-aware Network for Large Scale Multivariate Time Series Forecasting},
  year = {2023},
  month = oct,
  isbn = {9798400701245},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3583780.3615253},
  doi = {10.1145/3583780.3615253},
  abstract = {Large-scale Multivariate Time Series(MTS) widely exist in various real-world systems, imposing significant demands on model efficiency. A recent work, STID, addressed the high complexity issue of popular Spatial-Temporal Graph Neural Networks(STGNNs). Despite its success, when applied to large-scale MTS data, the number of parameters of STID for modeling spatial dependencies increases substantially, leading to over-parameterization issues and suboptimal performance. These observations motivate us to explore new approaches for modeling spatial dependencies in a parameter-friendly manner. In this paper, we argue that the spatial properties of variables are essentially the superposition of multiple cluster centers. Accordingly, we propose a Cluster-Aware Network(CANet), which effectively captures spatial dependencies by mining the implicit cluster centers of variables. CANet solely optimizes the cluster centers instead of the spatial information of all nodes, thereby significantly reducing the parameter amount. Extensive experiments on two large-scale datasets validate our motivation and demonstrate the superiority of CANet.},
  booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages = {4340-4344},
  numpages = {5},
  keywords = {multivariate time series forecasting, large-scale, cluster centers},
  location = {Birmingham, United Kingdom},
  series = {CIKM '23},
  google_scholar_id={R3hNpaxXUhUC},
  selected={false}
}

@article{WANG2023100405,
  bibtex_show={true},
  abbr={Innovation},
  title = {AI-enhanced spatial-temporal data-mining technology: New chance for next-generation urban computing},
  journal = {The Innovation},
  volume = {4},
  number = {2},
  pages = {100405},
  year = {2023},
  month = mar,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2023.100405},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675823000334},
  author = {Fei Wang* and Di Yao* and Yong Li* and Tao Sun and Zhao Zhang},
  google_scholar_id={mVmsd5A6BfQC},
  selected={true}
}

@INPROCEEDINGS{10446144,
  bibtex_show={true},
  abbr={ICASSP},
  author={Li, Yujie and Shao, Zezhi and Xu, Yongjun and Qiu, Qiang and Cao, Zhaogang and Wang, Fei},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Dynamic Frequency Domain Graph Convolutional Network for Traffic Forecasting}, 
  year={2024},
  month=apr,
  volume={},
  number={},
  pages={5245-5249},
  keywords={Convolution;Frequency-domain analysis;Time series analysis;Transportation;Traffic control;Spatial databases;Sensors;Traffic prediction;frequency domain signal processing;multivariate time series analysis;dynamic graph learning;graph convolution},
  doi={10.1109/ICASSP48485.2024.10446144},
  google_scholar_id={4JMBOYKVnBMC},
  selected={false}
}

@inproceedings{chen-etal-2024-self,
    bibtex_show={true},
    abbr={COLING},
    title = "Self-Improvement Programming for Temporal Knowledge Graph Question Answering",
    author = "Chen, Zhuo  and
      Zhang, Zhao  and
      Li, Zixuan  and
      Wang, Fei  and
      Zeng, Yutao  and
      Jin, Xiaolong  and
      Xu, Yongjun",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.1270/",
    pages = "14579--14594",
    abstract = "Temporal Knowledge Graph Question Answering (TKGQA) aims to answer questions with temporal intent over Temporal Knowledge Graphs (TKGs). The core challenge of this task lies in understanding the complex semantic information regarding multiple types of time constraints (e.g., before, first) in questions. Existing end-to-end methods implicitly model the time constraints by learning time-aware embeddings of questions and candidate answers, which is far from understanding the question comprehensively. Motivated by semantic-parsing-based approaches that explicitly model constraints in questions by generating logical forms with symbolic operators, we design fundamental temporal operators for time constraints and introduce a novel self-improvement Programming method for TKGQA (Prog-TQA). Specifically, Prog-TQA leverages the in-context learning ability of Large Language Models (LLMs) to understand the combinatory time constraints in the questions and generate corresponding program drafts with a few examples given. Then, it aligns these drafts to TKGs with the linking module and subsequently executes them to generate the answers. To enhance the ability to understand questions, Prog-TQA is further equipped with a self-improvement strategy to effectively bootstrap LLMs using high-quality self-generated drafts. Extensive experiments demonstrate the superiority of the proposed Prog-TQA on MultiTQ and CronQuestions datasets, especially in the Hits@1 metric.",
    google_scholar_id={r0BpntZqJG4C},
    selected={false}
}


@INPROCEEDINGS{10598115,
  bibtex_show={true},
  abbr={ICDE},
  author={Qian, Tangwen and Chen, Yile and Cong, Gao and Xu, Yongjun and Wang*, Fei},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={AdapTraj: A Multi-Source Domain Generalization Framework for Multi-Agent Trajectory Prediction}, 
  year={2024},
  month=may,
  volume={},
  number={},
  pages={5048-5060},
  keywords={Degradation;Adaptation models;Buildings;Predictive models;Data engineering;Data models;Trajectory;multi-agent trajectory prediction;multi-source domain generalization;distribution shift},
  doi={10.1109/ICDE60146.2024.00113},
  google_scholar_id={j3f4tGmQtD8C},
  selected={false}
  }


@inproceedings{10.1145/3637528.3672055,
  bibtex_show={true},
  abbr={KDD},
  author = {Yu, Chengqing and Wang*, Fei and Shao, Zezhi and Qian, Tangwen and Zhang, Zhao and Wei, Wei and Xu*, Yongjun},
  title = {GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing},
  year = {2024},
  month = aug,
  isbn = {9798400704901},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3637528.3672055},
  doi = {10.1145/3637528.3672055},
  abstract = {Multivariate time series forecasting (MTSF) is crucial for decision-making to precisely forecast the future values/trends, based on the complex relationships identified from historical observations of multiple sequences. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme of MTSF model as their powerful capability in mining spatial-temporal dependencies, but almost of them heavily rely on the assumption of historical data integrity. In reality, due to factors such as data collector failures and time-consuming repairment, it is extremely challenging to collect the whole historical observations without missing any variable. In this case, STGNNs can only utilize a subset of normal variables and easily suffer from the incorrect spatial-temporal dependency modeling issue, resulting in the degradation of their forecasting performance. To address the problem, in this paper, we propose a novel Graph Interpolation Attention Recursive Network (named GinAR) to precisely model the spatial-temporal dependencies over the limited collected data for forecasting. In GinAR, it consists of two key components, that is, interpolation attention and adaptive graph convolution to take place of the fully connected layer of simple recursive units, and thus are capable of recovering all missing variables and reconstructing the correct spatial-temporal dependencies for recursively modeling of multivariate time series data, respectively. Extensive experiments conducted on five real-world datasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when 90\% of variables are missing, it can still accurately predict the future values of all variables.},
  booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages = {3989-4000},
  numpages = {12},
  keywords = {adaptive graph convolution, graph interpolation attention recursive network, interpolation attention, multivariate time series forecasting, variable missing},
  location = {Barcelona, Spain},
  series = {KDD '24},
  google_scholar_id={iH-uZ7U-co4C},
  pdf={example_pdf.pdf},
  selected={false},
  code={https://github.com/GestaltCogTeam/GinAR}
}

@article{ZHAO2024100691,
  bibtex_show={true},
  abbr={Innovation},
  title = {Artificial intelligence for geoscience: Progress, challenges, and perspectives},
  journal = {The Innovation},
  volume = {5},
  number = {5},
  pages = {100691},
  year = {2024},
  month = sep,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100691},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824001292},
  author = {Tianjie Zhao† and Sheng Wang† and Chaojun Ouyang† and Min Chen† and Chenying Liu† and Jin Zhang† and Long Yu† and Fei Wang† and Yong Xie† and Jun Li† and Fang Wang and Sabine Grunwald and Bryan M. Wong and Fan Zhang and Zhen Qian and Yongjun Xu and Chengqing Yu and Wei Han and Tao Sun and Zezhi Shao and Tangwen Qian and Zhao Chen and Jiangyuan Zeng and Huai Zhang and Husi Letu and Bing Zhang and Li Wang and Lei Luo and Chong Shi and Hongjun Su and Hongsheng Zhang and Shuai Yin and Ni Huang and Wei Zhao and Nan Li and Chaolei Zheng and Yang Zhou and Changping Huang and Defeng Feng and Qingsong Xu and Yan Wu and Danfeng Hong and Zhenyu Wang and Yinyi Lin and Tangtang Zhang and Prashant Kumar and Antonio Plaza and Jocelyn Chanussot and Jiabao Zhang and Jiancheng Shi and Lizhe Wang*},
  keywords = {artificial intelligence, machine learning, deep learning, geoscience},
  abstract = {This paper explores the evolution of geoscientific inquiry, tracing the progression from traditional physics-based models to modern data-driven approaches facilitated by significant advancements in artificial intelligence (AI) and data collection techniques. Traditional models, which are grounded in physical and numerical frameworks, provide robust explanations by explicitly reconstructing underlying physical processes. However, their limitations in comprehensively capturing Earth’s complexities and uncertainties pose challenges in optimization and real-world applicability. In contrast, contemporary data-driven models, particularly those utilizing machine learning (ML) and deep learning (DL), leverage extensive geoscience data to glean insights without requiring exhaustive theoretical knowledge. ML techniques have shown promise in addressing Earth science-related questions. Nevertheless, challenges such as data scarcity, computational demands, data privacy concerns, and the “black-box” nature of AI models hinder their seamless integration into geoscience. The integration of physics-based and data-driven methodologies into hybrid models presents an alternative paradigm. These models, which incorporate domain knowledge to guide AI methodologies, demonstrate enhanced efficiency and performance with reduced training data requirements. This review provides a comprehensive overview of geoscientific research paradigms, emphasizing untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of AI in geoscience. The paper outlines a dynamic field ripe with possibilities, poised to unlock new understandings of Earth’s complexities and further advance geoscience exploration.},
  google_scholar_id={maZDTaKrznsC},
  selected={true}
}

@article{XU2024100725,
  bibtex_show={true},
  abbr={Innovation},
  title = {Artificial intelligence is restructuring a new world},
  journal = {The Innovation},
  volume = {5},
  number = {6},
  pages = {100725},
  year = {2024},
  month = nov,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100725},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824001632},
  author = {Yongjun Xu* and Fei Wang* and Tangtang Zhang*},
  google_scholar_id={XiSMed-E-HIC},
  selected={false}
}


@ARTICLE{10726722,
  bibtex_show={true},
  abbr={TKDE},
  author={Shao, Zezhi and Wang*, Fei and Xu*, Yongjun and Wei, Wei and Yu, Chengqing and Zhang, Zhao and Yao, Di and Sun, Tao and Jin, Guangyin and Cao, Xin and Cong, Gao and Jensen, Christian S. and Cheng*, Xueqi},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis}, 
  year={2025},
  month = jan,
  volume={37},
  number={1},
  pages={291-305},
  keywords={Forecasting;Time series analysis;Benchmark testing;Transformers;Predictive models;Data models;Computer science;Reliability;Proposals;Electricity;Benchmarking;multivariate time series;spatial-temporal forecasting;long-term time series forecasting},
  doi={10.1109/TKDE.2024.3484454},
  google_scholar_id={eJXPG6dFmWUC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/BasicTS},
  award={**BasicTS+ has acquired 1.3k+ Stars** 2025 *for the First, one of the Most Popular, fair and scalable benchmark of timeseries forecasting*},
  award_name={BasicTS+ has acquired 1.3k+ Stars}
}


@article{YU2025102607,
  bibtex_show={true},
  abbr={Information Fusion},
  title = {MGSFformer: A Multi-Granularity Spatiotemporal Fusion Transformer for air quality prediction},
  journal = {Information Fusion},
  volume = {113},
  pages = {102607},
  year = {2025},
  month = jan,
  issn = {1566-2535},
  doi = {https://doi.org/10.1016/j.inffus.2024.102607},
  url = {https://www.sciencedirect.com/science/article/pii/S1566253524003853},
  author = {Chengqing Yu and Fei Wang* and Yilun Wang and Zezhi Shao and Tao Sun and Di Yao and Yongjun Xu*},
  keywords = {Air quality prediction, Multi-Granularity Spatiotemporal Fusion Transformer, Spatiotemporal correlation, Multi-source information fusion},
  abstract = {Air quality spatiotemporal prediction can provide technical support for environmental governance and sustainable city development. As a classic multi-source spatiotemporal data, effective multi-source information fusion is key to achieving accurate air quality predictions. However, due to not fully fusing two pieces of information, classical deep learning models struggle to achieve satisfactory prediction results: (1) Multi-granularity: each air monitoring station collects air quality data at different sampling intervals, which show distinct time series patterns. (2) Spatiotemporal correlation: due to human activities and atmospheric diffusion, there exist correlations between air quality data from different air monitoring stations, necessitating the consideration of other air monitoring stations' influences when modeling each air quality time series. In this study, to achieve satisfactory prediction results, we propose the Multi-Granularity Spatiotemporal Fusion Transformer, comprised of the residual de-redundant block, spatiotemporal attention block, and dynamic fusion block. Specifically, the residual de-redundant block eliminates information redundancy between data with different granularities and prevents the model from being misled by redundant information. The spatiotemporal attention block captures the spatiotemporal correlation of air quality data and facilitates prediction modeling. The dynamic fusion block evaluates the importance of data with different granularities and integrates the prediction results. Experimental results demonstrate that the proposed model surpasses 11 baselines by 5% in performance on three real-world datasets.},
  google_scholar_id={isC4tDSrTZIC},
  selected={false}
}
@article{LI2025110978,
  bibtex_show={true},
  abbr={PR},
  title = {Trajectory-User Linking via Multi-Scale Graph Attention Network},
  journal = {Pattern Recognition},
  volume = {158},
  pages = {110978},
  year = {2025},
  month = feb,
  issn = {0031-3203},
  doi = {https://doi.org/10.1016/j.patcog.2024.110978},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320324007295},
  author = {Yujie Li and Tao Sun and Zezhi Shao and Yiqiang Zhen and Yongjun Xu and Fei Wang*},
  keywords = {Trajectory-user linking, Graph neural network, Trajectory classification, Spatio-temporal data mining, Check-in data},
  abstract = {Trajectory-User Linking (TUL) aims to link anonymous trajectories to their owners, which is considered an essential task in discovering human mobility patterns. Although existing TUL studies have shown promising results, they still have specific defects in the perception of spatio-temporal properties of trajectories, which manifested in the following three problems: missing context of the original trajectory, ignorance of spatial information, and high computational complexity. To address those issues, we revisit the characteristics of the trajectory and propose a novel model called TULMGAT (TUL via Multi-Scale Graph Attention Network) based on masked self-attention graph neural networks. Specifically, TULMGAT consists of four components: construction of check-in oriented graphs, node embedding, trajectory embedding, and trajectory user linking. Sufficient experiments on two publicly available datasets have shown that TULMGAT is the state-of-the-art model in task TUL compared to the baselines with an improvement of about 8% in accuracy and only a quarter of the fastest baseline in runtime. Furthermore, model validity experiments have verified the role of each module.},
  google_scholar_id={M3NEmzRMIkIC},
  selected={false}
}

@article{ZHANG2025100775,
  bibtex_show={true},
  abbr={Innovation},
  title = {MetaCity: Data-driven sustainable development of complex cities},
  journal = {The Innovation},
  volume = {6},
  number = {2},
  pages = {100775},
  year = {2025},
  month= feb,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100775},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824002133},
  author = {Yunke Zhang and Yuming Lin and Guanjie Zheng and Yu Liu and Nicholas Sukiennik and Fengli Xu and Yongjun Xu and Feng Lu and Qi Wang and Yuan Lai and Li Tian and Nan Li and Dongping Fang and Fei Wang* and Tao Zhou* and Yong Li* and Yu Zheng and Zhiqiang Wu and Huadong Guo},
  keywords = {urban complex systems, sustainable development, data-driven methods, artificial intelligence},
  abstract = {Cities are complex systems that develop under complicated interactions among their human and environmental components. Urbanization generates substantial outcomes and opportunities while raising challenges including congestion, air pollution, inequality, etc., calling for efficient and reasonable solutions to sustainable developments. Fortunately, booming technologies generate large-scale data of complex cities, providing a chance to propose data-driven solutions for sustainable urban developments. This paper provides a comprehensive overview of data-driven urban sustainability practice. In this review article, we conceptualize MetaCity, a general framework for optimizing resource usage and allocation problems in complex cities with data-driven approaches. Under this framework, we decompose specific urban sustainable goals, e.g., efficiency and resilience, review practical urban problems under these goals, and explore the probability of using data-driven technologies as potential solutions to the challenge of complexity. On the basis of extensive urban data, we integrate urban problem discovery, operation of urban systems simulation, and complex decision-making problem solving into an entire cohesive framework to achieve sustainable development goals by optimizing resource allocation problems in complex cities.},
  google_scholar_id={VOx2b1Wkg3QC},
  selected={false}
}

@article{SHAO2025100763,
  bibtex_show={true},
  abbr={Innovation},
  title = {Spatial-temporal large models: A super hub linking multiple scientific areas with artificial intelligence},
  journal = {The Innovation},
  volume = {6},
  number = {2},
  pages = {100763},
  year = {2025},
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100763},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824002017},
  author = {Zezhi Shao and Tangwen Qian and Tao Sun and Fei Wang* and Yongjun Xu*},
  google_scholar_id={8AbLer7MMksC},
  selected={false}
}

@article{CHEN2025100780,
  bibtex_show={true},
  abbr={Innovation},
  title = {Toward the robustness of autonomous vehicles in the AI era},
  journal = {The Innovation},
  volume = {6},
  number = {3},
  pages = {100780},
  year = {2025},
  month = mar,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100780},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824002182},
  author = {Siheng Chen* and Yiyi Liao* and Fei Wang* and Gang Wang* and Liang Wang* and Yafei Wang* and Xichan Zhu*},
  google_scholar_id={LPZeul_q3PIC},
  selected={false}
}


@article{WU2025100832,
  bibtex_show={true},
  abbr={Innovation},
  title = {Toward more economical large-scale foundation models: No longer a game for the few},
  journal = {The Innovation},
  volume = {6},
  number = {4},
  pages = {100832},
  year = {2025},
  month= apr,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2025.100832},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675825000359},
  author = {Yiqing Wu and Zhao Zhang* and Fei Wang and Yongjun Xu* and Jincai Huang},
  google_scholar_id={eflP2zaiRacC},
  selected={false}
}



@article{Zhou_Wei_Cao_Wang_2025, 
  bibtex_show={true},
  abbr={AAAI},
  title={Editing Memories Through Few Targeted Neurons}, 
  volume={39}, 
  url={https://ojs.aaai.org/index.php/AAAI/article/view/34807}, 
  DOI={10.1609/aaai.v39i24.34807}, 
  abstractN={Model editing is a novel research topic in large language models (LLMs), aimed at efficiently handling various knowledge editing tasks. Since irrelevant knowledge is difficult to measure,existing editing methods often lack explicit ways to preserve it, especially for editing methods based on the fine-tuning paradigm. They generally control the locality performance of model editing by constraining the range of changes in model parameters. However, their performance improvements are not always ideal, and may even lead to a decrease in the editing reliability. In this paper, we try to explore effective editing locality control methods based on the relationship between the stored knowledge and the strongly associated model components. Based on the discovery of ``knowledge neurons’’ and enough experimental results, we further explore the potential characteristics between knowledge and model components, confirm and point out: (1) only 1% neurons have significant contributions to specific knowledge storage, and (2) these targeted neurons often have a high overlap for knowledge with similar relational descriptions, which means that knowledge with similar relationships may be severely affected when these targeted neurons are modified. Based on these findings, we propose Targeted Neurons Fine-tuning with Data Augmentation (TNF-DA), which performs data augmentation based on the relational representation of edited knowledge to improve editing locality. By freezing most of the model parameters and only fine-tuning the highly contributing neurons corresponding to the edited knowledge, we obtain desirable results in terms of generalization and specificity compared with previous fine-tuning-based methods. Extensive experiments have demonstrated the superior editing performance achieved by our proposed method.}, 
  number={24}, 
  journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
  author={Zhou, Wei and Wei, Wei and Cao, Guibang and Wang, Fei}, 
  year={2025}, 
  month=Apr, 
  pages={26111-26119},
  google_scholar_id={BrmTIyaxlBUC},
  selected={false}
}

@article{Feng_Qin_Yang_An_Huang_Diao_Wang_Tao_Xu_Magno_2025, 
  bibtex_show={true},
  abbr={AAAI},
  title={MPQ-DM: Mixed Precision Quantization for Extremely Low Bit Diffusion Models}, 
  volume={39}, 
  url={https://ojs.aaai.org/index.php/AAAI/article/view/33823}, 
  DOI={10.1609/aaai.v39i16.33823}, 
  abstract={Diffusion models have received wide attention in generation tasks. However, the expensive computation cost prevents the application of diffusion models in resource-constrained scenarios. Quantization emerges as a practical solution that significantly saves storage and computation by reducing the bit-width of parameters. However, the existing quantization methods for diffusion models still cause severe degradation in performance, especially under extremely low bit-widths (2-4 bit). The primary decrease in performance comes from the significant discretization of activation values at low bit quantization. Too few activation candidates are unfriendly for outlier significant weight channel quantization, and the discretized features prevent stable learning over different time steps of the diffusion model. This paper presents MPQ-DM, a Mixed-Precision Quantization method for Diffusion Models. The proposed MPQ-DM mainly relies on two techniques: (1) To mitigate the quantization error caused by outlier severe weight channels, we propose an Outlier-Driven Mixed Quantization (OMQ) technique that uses Kurtosis to quantify outlier salient channels and apply optimized intra-layer mixed-precision bit-width allocation to recover accuracy performance within target efficiency. (2) To robustly learn representations crossing time steps, we construct a Time-Smoothed Relation Distillation (TRD) scheme between the quantized diffusion model and its full-precision counterpart, transferring discrete and continuous latent to a unified relation space to reduce the representation inconsistency. Comprehensive experiments demonstrate that MPQ-DM achieves significant accuracy gains under extremely low bit-widths compared with SOTA quantization methods. MPQ-DM achieves a 58% FID decrease under W2A4 setting compared with baseline, while all other methods even collapse.}, number={16}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Feng, Weilun and Qin, Haotong and Yang, Chuanguang and An, Zhulin and Huang, Libo and Diao, Boyu and Wang, Fei and Tao, Renshuai and Xu, Yongjun and Magno, Michele}, 
  year={2025}, 
  month=Apr, 
  pages={16595-16603}, 
  google_scholar_id={5Ul4iDaHHb8C},
  selected={false}
}


@Article{JCST-2212-13013,
  bibtex_show={true},
  abbr={JCST},
  title = {A Model-Agnostic Hierarchical Framework Towards Trajectory Prediction},
  journal = {Journal of Computer Science and Technology},
  volume = {40},
  number = {2},
  pages = {322-339},
  year = {2025},
  month=may,
  issn = {1000-9000(Print) /1860-4749(Online)},
  doi = {10.1007/s11390-023-3013-4},	
  url = {https://jcst.ict.ac.cn/en/article/doi/10.1007/s11390-023-3013-4},
  author = {Tang-Wen Qian and Yuan Wang and Yong-Jun Xu and Zhao Zhang and Lin Wu and Qiang Qiu and Fei Wang*},
  abstract = {<p>Predicting the future trajectories of multiple agents is essential for various applications in real life, such as surveillance systems, autonomous driving, and social robots. The trajectory prediction task is influenced by many factors, including the individual historical trajectory, interactions between agents, and the fuzzy nature of the observed agents’ motion. While existing methods have made great progress on the topic of trajectory prediction, they treat all the information uniformly, which limits the effectiveness of information utilization. To this end, in this paper, we propose and utilize a model-agnostic framework to regard all the information in a two-level hierarchical view. Particularly, the first-level view is the inter-trajectory view. In this level, we observe that the difficulty in predicting different trajectory samples varies. We define trajectory difficulty and train the proposed framework in an “easy-to-hard” schema. The second-level view is the intra-trajectory level. We find the influencing factors for a particular trajectory can be divided into two parts. The first part is global features, which keep stable within a trajectory, i.e., the expected destination. The second part is local features, which change over time, i.e., the current position. We believe that the two types of information should be handled in different ways. The hierarchical view is beneficial to take full advantage of the information in a fine-grained way. Experimental results validate the effectiveness of the proposed model-agnostic framework.</p>},
  google_scholar_id={HDshCWvjkbEC},
  selected={false}
}


@ARTICLE{10981648,
  bibtex_show={true},
  abbr={TKDE},
  author={Guan, Zhanpeng and Zhang, Fuwei and Zhang, Zhao and Zhuang, Fuzhen and Wang, Fei and An, Zhulin and Xu, Yongjun},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={AdaE: Knowledge Graph Embedding with Adaptive Embedding Sizes}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  keywords={Knowledge graphs;Adaptation models;Training;Data models;Search problems;Vectors;Overfitting;Tail;Optimization;Tensors;Knowledge graph embedding;Data imbalance issue;Dimension selection},
  doi={10.1109/TKDE.2025.3566270},
  google_scholar_id={q3oQSFYPqjQC},
  selected={false}
  }



@ARTICLE{11002729,
  bibtex_show={true},
  abbr={TKDE},
  author={Yu, Chengqing and Wang*, Fei and Shao, Zezhi and Qian, Tangwen and Zhang, Zhao and Wei, Wei and An, Zhulin and Wang, Qi and Xu, Yongjun},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={GinAR+: A Robust End-To-End Framework for Multivariate Time Series Forecasting with Missing Values}, 
  year={2025},
  month=may,
  volume={},
  number={},
  pages={1-14},
  keywords={Correlation;Predictive models;Forecasting;Time series analysis;Data models;Robustness;Adaptation models;Imputation;Contrastive learning;Training;Contrastive learning;Graph interpolation attention recursive network;Multivariate Time Series Forecasting with Missing Values},
  doi={10.1109/TKDE.2025.3569649},
  google_scholar_id={XiVPGOgt02cC},
  selected={false}
}

@article{HUANG2025100948,
  bibtex_show={true},
  abbr={Innovation},
  title = {Foundation models and intelligent decision-making: Progress, challenges, and perspectives},
  journal = {The Innovation},
  volume = {6},
  number = {6},
  pages = {100948},
  year = {2025},
  month = jun,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2025.100948},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675825001511},
  author = {Jincai Huang† and Yongjun Xu† and Qi Wang† and Qi (Cheems) Wang† and Xingxing Liang† and Fei Wang† and Zhao Zhang† and Wei Wei† and Boxuan Zhang† and Libo Huang† and Jingru Chang† and Liantao Ma† and Ting Ma† and Yuxuan Liang† and Jie Zhang† and Jian Guo† and Xuhui Jiang† and Xinxin Fan† and Zhulin An† and Tingting Li† and Xuefei Li and Zezhi Shao and Tangwen Qian and Tao Sun and Boyu Diao and Chuanguang Yang and Chenqing Yu and Yiqing Wu and Mengxian Li and Haifeng Zhang and Yongcheng Zeng and Zhicheng Zhang and Zhengqiu Zhu and Yiqin Lv and Aming Li and Xu Chen and Bo An and Wei Xiao and Chenguang Bai and Yuxing Mao and Zhigang Yin and Sheng Gui and Wentao Su and Yinghao Zhu and Junyi Gao and Xinyu He and Yizhou Li and Guangyin Jin and Xiang Ao and Xuehao Zhai and Haoran Tan and Lijun Yun and Hongquan Shi and Jun Li and Changjun Fan and Kuihua Huang and Ewen Harrison and Victor C.M. Leung and Sihang Qiu and Yanjie Dong and Xiaolong Zheng and Gang Wang and Yu Zheng and Yuanzhuo Wang and Jiafeng Guo and Lizhe Wang and Xueqi Cheng and Yaonan Wang and Shanlin Yang and Mengyin Fu and Aiguo Fei},
  keywords = {artificial intelligence, intelligent decision-making, foundation models, agent, large language model},
  abstract = {Intelligent decision-making (IDM) is a cornerstone of artificial intelligence (AI) designed to automate or augment decision processes. Modern IDM paradigms integrate advanced frameworks to enable intelligent agents to make effective and adaptive choices and decompose complex tasks into manageable steps, such as AI agents and high-level reinforcement learning. Recent advances in multimodal foundation-based approaches unify diverse input modalities—such as vision, language, and sensory data—into a cohesive decision-making process. Foundation models (FMs) have become pivotal in science and industry, transforming decision-making and research capabilities. Their large-scale, multimodal data-processing abilities foster adaptability and interdisciplinary breakthroughs across fields such as healthcare, life sciences, and education. This survey examines IDM’s evolution, advanced paradigms with FMs and their transformative impact on decision-making across diverse scientific and industrial domains, highlighting the challenges and opportunities in building efficient, adaptive, and ethical decision systems.},
  google_scholar_id={mvPsJ3kp5DgC},
  selected={true}
}


@inproceedings{blast,
  bibtex_show={true},
  abbr={KDD},
  author = {Shao, Zezhi and Li, Yujie and Wang*, Fei and Yu, Chengqing and Fu, Yisong and Qian, Tangwen and Xu, Bin and Diao, Boyu and Xu, Yongjun and Cheng, Xueqi},
  title = {BLAST: Balanced Sampling Time Series Corpus for Universal Forecasting Models},
  year = {2025},
  month = aug,
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  abstract = {The advent of universal time series forecasting models has revolutionized zero-shot forecasting across diverse domains, yet the critical role of data diversity in training these models remains underexplored. Existing large-scale time series datasets often suffer from inherent biases and imbalanced distributions, leading to suboptimal model performance and generalization. To address this gap, we introduce BLAST, a novel pre-training corpus designed to enhance data diversity through a balanced sampling strategy. First, BLAST incorporates 321 billion observations from publicly available datasets and employs a comprehensive suite of statistical metrics to characterize time series patterns. Then, to facilitate pattern-oriented sampling, the data is implicitly clustered using grid-based partitioning. Furthermore, by integrating grid sampling and grid mixup techniques, BLAST ensures a balanced and representative coverage of diverse patterns. Experimental results demonstrate that models pre-trained on BLAST achieve state-of-the-art performance with a fraction of the computational resources and training tokens required by existing methods. Our findings highlight the pivotal role of data diversity in improving both training efficiency and model performance for the universal forecasting task.},
  booktitle = {Proceedings of the 31th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  keywords = {large-scale time series dataset, balanced sampling, universal time series forecasting},
  location = {Toronton, ON, Canada},
  series = {KDD '25},
  google_scholar_id={t6usbXjVLHcC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/BLAST}
}
