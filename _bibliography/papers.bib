---
---

@article{XU2021100179,
  bibtex_show={true},
  abbr={Innovation},
  title = {Artificial intelligence: A powerful paradigm for scientific research},
  journal = {The Innovation},
  volume = {2},
  number = {4},
  pages = {100179},
  year = {2021},
  month = nov,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2021.100179},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675821001041},
  author = {Yongjun Xu and Xin Liu and Xin Cao and Changping Huang and Enke Liu and Sen Qian and Xingchen Liu and Yanjun Wu and Fengliang Dong and Cheng-Wei Qiu and Junjun Qiu and Keqin Hua and Wentao Su and Jian Wu and Huiyu Xu and Yong Han and Chenguang Fu and Zhigang Yin and Miao Liu and Ronald Roepman and Sabine Dietmann and Marko Virta and Fredrick Kengara and Ze Zhang and Lifu Zhang and Taolan Zhao and Ji Dai and Jialiang Yang and Liang Lan and Ming Luo and Zhaofeng Liu and Tao An and Bin Zhang and Xiao He and Shan Cong and Xiaohong Liu and Wei Zhang and James P. Lewis and James M. Tiedje and Qi Wang* and Zhulin An* and Fei Wang* and Libo Zhang* and Tao Huang* and Chuan Lu* and Zhipeng Cai* and Fang Wang* and Jiabao Zhang*},
  keywords = {artificial intelligence, machine learning, deep learning, information science, mathematics, medical science, materials science, geoscience, life science, physics, chemistry},
  abstract = {Artificial intelligence (AI) coupled with promising machine learning (ML) techniques well known from computer science is broadly affecting many aspects of various fields including science and technology, industry, and even our day-to-day life. The ML techniques have been developed to analyze high-throughput data with a view to obtaining useful insights, categorizing, predicting, and making evidence-based decisions in novel ways, which will promote the growth of novel applications and fuel the sustainable booming of AI. This paper undertakes a comprehensive survey on the development and application of AI in different aspects of fundamental sciences, including information science, mathematics, medical science, materials science, geoscience, life science, physics, and chemistry. The challenges that each discipline of science meets, and the potentials of AI techniques to handle these challenges, are discussed in detail. Moreover, we shed light on new research trends entailing the integration of AI into each scientific discipline. The aim of this paper is to provide a broad research guideline on fundamental sciences with potential infusion of AI, to help motivate researchers to deeply understand the state-of-the-art applications of AI-based fundamental sciences, and thereby to help promote the continuous development of these fundamental sciences.},
  google_scholar_id={8k81kl-MbHgC},
  selected={true}
}


@inproceedings{10.1145/3534678.3539396,
  bibtex_show={true},
  abbr={KDD},
  author = {Shao, Zezhi and Zhang, Zhao and Wang*, Fei and Xu, Yongjun},
  title = {Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting},
  year = {2022},
  month = aug,
  isbn = {9781450393850},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3534678.3539396},
  doi = {10.1145/3534678.3539396},
  abstract = {Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns.},
  booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages = {1567-1577},
  numpages = {11},
  keywords = {multivariate time series forecasting, pre-training model, spatial-temporal graph neural network},
  location = {Washington DC, USA},
  series = {KDD '22},
  google_scholar_id={HE397vMXCloC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/STEP}
}

@article{10.14778/3551793.3551827,
  bibtex_show={true},
  abbr={VLDB},
  author = {Shao, Zezhi and Zhang, Zhao and Wei*, Wei and Wang*, Fei and Xu, Yongjun and Cao, Xin and Jensen, Christian S.},
  title = {Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting},
  year = {2022},
  publisher = {VLDB Endowment},
  volume = {15},
  number = {11},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3551793.3551827},
  doi = {10.14778/3551793.3551827},
  abstract = {We all depend on mobility, and vehicular transportation affects the daily lives of most of us. Thus, the ability to forecast the state of traffic in a road network is an important functionality and a challenging task. Traffic data is often obtained from sensors deployed in a road network. Recent proposals on spatial-temporal graph neural networks have achieved great progress at modeling complex spatial-temporal correlations in traffic data, by modeling traffic data as a diffusion process. However, intuitively, traffic data encompasses two different kinds of hidden time series signals, namely the diffusion signals and inherent signals. Unfortunately, nearly all previous works coarsely consider traffic signals entirely as the outcome of the diffusion, while neglecting the inherent signals, which impacts model performance negatively. To improve modeling performance, we propose a novel Decoupled Spatial-Temporal Framework (DSTF) that separates the diffusion and inherent traffic information in a data-driven manner, which encompasses a unique estimation gate and a residual decomposition mechanism. The separated signals can be handled subsequently by the diffusion and inherent modules separately. Further, we propose an instantiation of DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network (D2STGNN), that captures spatial-temporal correlations and also features a dynamic graph learning module that targets the learning of the dynamic characteristics of traffic networks. Extensive experiments with four real-world traffic datasets demonstrate that the framework is capable of advancing the state-of-the-art.},
  journal = {Proc. VLDB Endow.},
  month = jul,
  pages = {2733-2746},
  numpages = {14},
  google_scholar_id={D_sINldO8mEC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/D2STGNN}
}

@inproceedings{10.1145/3511808.3557702,
  bibtex_show={true},
  abbr={CIKM},
  author = {Shao, Zezhi and Zhang, Zhao and Wang*, Fei and Wei, Wei and Xu, Yongjun},
  title = {Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting},
  year = {2022},
  month = oct,
  isbn = {9781450392365},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3511808.3557702},
  doi = {10.1145/3511808.3557702},
  abstract = {Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods due to their state-of-the-art performance. However, recent works are becoming more sophisticated with limited performance improvements. This phenomenon motivates us to explore the critical factors of MTS forecasting and design a model that is as powerful as STGNNs, but more concise and efficient. In this paper, we identify the indistinguishability of samples in both spatial and temporal dimensions as a key bottleneck, and propose a simple yet effective baseline for MTS forecasting by attaching <u>S</u>patial and <u>T</u>emporal <u>ID</u>entity information (STID), which achieves the best performance and efficiency simultaneously based on simple Multi-Layer Perceptrons (MLPs). These results suggest that we can design efficient and effective models as long as they solve the indistinguishability of samples, without being limited to STGNNs.},
  booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages = {4454-4458},
  numpages = {5},
  keywords = {spatial-temporal graph neural network, multivariate time series forecasting, baseline},
  location = {Atlanta, GA, USA},
  series = {CIKM '22},
  google_scholar_id={4TOpqqG69KYC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/STID}
}

@inproceedings{10.1145/3637528.3672055,
  bibtex_show={true},
  abbr={KDD},
  author = {Yu, Chengqing and Wang*, Fei and Shao, Zezhi and Qian, Tangwen and Zhang, Zhao and Wei, Wei and Xu*, Yongjun},
  title = {GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing},
  year = {2024},
  month = aug,
  isbn = {9798400704901},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3637528.3672055},
  doi = {10.1145/3637528.3672055},
  abstract = {Multivariate time series forecasting (MTSF) is crucial for decision-making to precisely forecast the future values/trends, based on the complex relationships identified from historical observations of multiple sequences. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme of MTSF model as their powerful capability in mining spatial-temporal dependencies, but almost of them heavily rely on the assumption of historical data integrity. In reality, due to factors such as data collector failures and time-consuming repairment, it is extremely challenging to collect the whole historical observations without missing any variable. In this case, STGNNs can only utilize a subset of normal variables and easily suffer from the incorrect spatial-temporal dependency modeling issue, resulting in the degradation of their forecasting performance. To address the problem, in this paper, we propose a novel Graph Interpolation Attention Recursive Network (named GinAR) to precisely model the spatial-temporal dependencies over the limited collected data for forecasting. In GinAR, it consists of two key components, that is, interpolation attention and adaptive graph convolution to take place of the fully connected layer of simple recursive units, and thus are capable of recovering all missing variables and reconstructing the correct spatial-temporal dependencies for recursively modeling of multivariate time series data, respectively. Extensive experiments conducted on five real-world datasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when 90\% of variables are missing, it can still accurately predict the future values of all variables.},
  booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages = {3989-4000},
  numpages = {12},
  keywords = {adaptive graph convolution, graph interpolation attention recursive network, interpolation attention, multivariate time series forecasting, variable missing},
  location = {Barcelona, Spain},
  series = {KDD '24},
  google_scholar_id={iH-uZ7U-co4C},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/GinAR}
}

@ARTICLE{10726722,
  bibtex_show={true},
  abbr={TKDE},
  author={Shao, Zezhi and Wang*, Fei and Xu*, Yongjun and Wei, Wei and Yu, Chengqing and Zhang, Zhao and Yao, Di and Sun, Tao and Jin, Guangyin and Cao, Xin and Cong, Gao and Jensen, Christian S. and Cheng*, Xueqi},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis}, 
  year={2024},
  month = oct,
  volume={37},
  number={1},
  pages={291-305},
  keywords={Forecasting;Time series analysis;Benchmark testing;Transformers;Predictive models;Data models;Computer science;Reliability;Proposals;Electricity;Benchmarking;multivariate time series;spatial-temporal forecasting;long-term time series forecasting},
  doi={10.1109/TKDE.2024.3484454},
  google_scholar_id={eJXPG6dFmWUC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/BasicTS}
}

@article{XU2024100725,
  bibtex_show={true},
  abbr={Innovation},
  title = {Artificial intelligence is restructuring a new world},
  journal = {The Innovation},
  volume = {5},
  number = {6},
  pages = {100725},
  year = {2024},
  month = nov,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100725},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824001632},
  author = {Yongjun Xu* and Fei Wang* and Tangtang Zhang*},
  google_scholar_id={XiSMed-E-HIC},
  selected={false}
}


@inproceedings{blast,
  bibtex_show={true},
  abbr={KDD},
  author = {Shao, Zezhi and Li, Yujie and Wang*, Fei and Yu, Chengqing and Fu, Yisong and Qian, Tangwen and Xu, Bin and Diao, Boyu and Xu, Yongjun and Cheng, Xueqi},
  title = {BLAST: Balanced Sampling Time Series Corpus for Universal Forecasting Models},
  year = {2025},
  month = aug,
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  abstract = {The advent of universal time series forecasting models has revolutionized zero-shot forecasting across diverse domains, yet the critical role of data diversity in training these models remains underexplored. Existing large-scale time series datasets often suffer from inherent biases and imbalanced distributions, leading to suboptimal model performance and generalization. To address this gap, we introduce BLAST, a novel pre-training corpus designed to enhance data diversity through a balanced sampling strategy. First, BLAST incorporates 321 billion observations from publicly available datasets and employs a comprehensive suite of statistical metrics to characterize time series patterns. Then, to facilitate pattern-oriented sampling, the data is implicitly clustered using grid-based partitioning. Furthermore, by integrating grid sampling and grid mixup techniques, BLAST ensures a balanced and representative coverage of diverse patterns. Experimental results demonstrate that models pre-trained on BLAST achieve state-of-the-art performance with a fraction of the computational resources and training tokens required by existing methods. Our findings highlight the pivotal role of data diversity in improving both training efficiency and model performance for the universal forecasting task.},
  booktitle = {Proceedings of the 31th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  keywords = {large-scale time series dataset, balanced sampling, universal time series forecasting},
  location = {Toronton, ON, Canada},
  series = {KDD '25},
  google_scholar_id={t6usbXjVLHcC},
  pdf={example_pdf.pdf},
  selected={true},
  code={https://github.com/GestaltCogTeam/BLAST}
}

@article{YU2025102607,
  bibtex_show={true},
  abbr={Information Fusion},
  title = {MGSFformer: A Multi-Granularity Spatiotemporal Fusion Transformer for air quality prediction},
  journal = {Information Fusion},
  volume = {113},
  pages = {102607},
  year = {2025},
  month = jan,
  issn = {1566-2535},
  doi = {https://doi.org/10.1016/j.inffus.2024.102607},
  url = {https://www.sciencedirect.com/science/article/pii/S1566253524003853},
  author = {Chengqing Yu and Fei Wang* and Yilun Wang and Zezhi Shao and Tao Sun and Di Yao and Yongjun Xu*},
  keywords = {Air quality prediction, Multi-Granularity Spatiotemporal Fusion Transformer, Spatiotemporal correlation, Multi-source information fusion},
  abstract = {Air quality spatiotemporal prediction can provide technical support for environmental governance and sustainable city development. As a classic multi-source spatiotemporal data, effective multi-source information fusion is key to achieving accurate air quality predictions. However, due to not fully fusing two pieces of information, classical deep learning models struggle to achieve satisfactory prediction results: (1) Multi-granularity: each air monitoring station collects air quality data at different sampling intervals, which show distinct time series patterns. (2) Spatiotemporal correlation: due to human activities and atmospheric diffusion, there exist correlations between air quality data from different air monitoring stations, necessitating the consideration of other air monitoring stations' influences when modeling each air quality time series. In this study, to achieve satisfactory prediction results, we propose the Multi-Granularity Spatiotemporal Fusion Transformer, comprised of the residual de-redundant block, spatiotemporal attention block, and dynamic fusion block. Specifically, the residual de-redundant block eliminates information redundancy between data with different granularities and prevents the model from being misled by redundant information. The spatiotemporal attention block captures the spatiotemporal correlation of air quality data and facilitates prediction modeling. The dynamic fusion block evaluates the importance of data with different granularities and integrates the prediction results. Experimental results demonstrate that the proposed model surpasses 11 baselines by 5% in performance on three real-world datasets.},
  google_scholar_id={isC4tDSrTZIC},
  selected={true}
}
@article{LI2025110978,
  bibtex_show={true},
  abbr={PR},
  title = {Trajectory-User Linking via Multi-Scale Graph Attention Network},
  journal = {Pattern Recognition},
  volume = {158},
  pages = {110978},
  year = {2025},
  month = feb,
  issn = {0031-3203},
  doi = {https://doi.org/10.1016/j.patcog.2024.110978},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320324007295},
  author = {Yujie Li and Tao Sun and Zezhi Shao and Yiqiang Zhen and Yongjun Xu and Fei Wang*},
  keywords = {Trajectory-user linking, Graph neural network, Trajectory classification, Spatio-temporal data mining, Check-in data},
  abstract = {Trajectory-User Linking (TUL) aims to link anonymous trajectories to their owners, which is considered an essential task in discovering human mobility patterns. Although existing TUL studies have shown promising results, they still have specific defects in the perception of spatio-temporal properties of trajectories, which manifested in the following three problems: missing context of the original trajectory, ignorance of spatial information, and high computational complexity. To address those issues, we revisit the characteristics of the trajectory and propose a novel model called TULMGAT (TUL via Multi-Scale Graph Attention Network) based on masked self-attention graph neural networks. Specifically, TULMGAT consists of four components: construction of check-in oriented graphs, node embedding, trajectory embedding, and trajectory user linking. Sufficient experiments on two publicly available datasets have shown that TULMGAT is the state-of-the-art model in task TUL compared to the baselines with an improvement of about 8% in accuracy and only a quarter of the fastest baseline in runtime. Furthermore, model validity experiments have verified the role of each module.},
  google_scholar_id={M3NEmzRMIkIC},
  selected={false}
}

@article{ZHANG2025100775,
  bibtex_show={true},
  abbr={Innovation},
  title = {MetaCity: Data-driven sustainable development of complex cities},
  journal = {The Innovation},
  volume = {6},
  number = {2},
  pages = {100775},
  year = {2025},
  month= feb,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100775},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824002133},
  author = {Yunke Zhang and Yuming Lin and Guanjie Zheng and Yu Liu and Nicholas Sukiennik and Fengli Xu and Yongjun Xu and Feng Lu and Qi Wang and Yuan Lai and Li Tian and Nan Li and Dongping Fang and Fei Wang* and Tao Zhou* and Yong Li* and Yu Zheng and Zhiqiang Wu and Huadong Guo},
  keywords = {urban complex systems, sustainable development, data-driven methods, artificial intelligence},
  abstract = {Cities are complex systems that develop under complicated interactions among their human and environmental components. Urbanization generates substantial outcomes and opportunities while raising challenges including congestion, air pollution, inequality, etc., calling for efficient and reasonable solutions to sustainable developments. Fortunately, booming technologies generate large-scale data of complex cities, providing a chance to propose data-driven solutions for sustainable urban developments. This paper provides a comprehensive overview of data-driven urban sustainability practice. In this review article, we conceptualize MetaCity, a general framework for optimizing resource usage and allocation problems in complex cities with data-driven approaches. Under this framework, we decompose specific urban sustainable goals, e.g., efficiency and resilience, review practical urban problems under these goals, and explore the probability of using data-driven technologies as potential solutions to the challenge of complexity. On the basis of extensive urban data, we integrate urban problem discovery, operation of urban systems simulation, and complex decision-making problem solving into an entire cohesive framework to achieve sustainable development goals by optimizing resource allocation problems in complex cities.},
  google_scholar_id={VOx2b1Wkg3QC},
  selected={true}
}

@article{SHAO2025100763,
  bibtex_show={true},
  abbr={Innovation},
  title = {Spatial-temporal large models: A super hub linking multiple scientific areas with artificial intelligence},
  journal = {The Innovation},
  volume = {6},
  number = {2},
  pages = {100763},
  year = {2025},
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100763},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824002017},
  author = {Zezhi Shao and Tangwen Qian and Tao Sun and Fei Wang* and Yongjun Xu*},
  google_scholar_id={8AbLer7MMksC},
  selected={true}
}

@article{CHEN2025100780,
  bibtex_show={true},
  abbr={Innovation},
  title = {Toward the robustness of autonomous vehicles in the AI era},
  journal = {The Innovation},
  volume = {6},
  number = {3},
  pages = {100780},
  year = {2025},
  month = mar,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2024.100780},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675824002182},
  author = {Siheng Chen* and Yiyi Liao* and Fei Wang* and Gang Wang* and Liang Wang* and Yafei Wang* and Xichan Zhu*},
  google_scholar_id={LPZeul_q3PIC},
  selected={true}
}


@article{WU2025100832,
  bibtex_show={true},
  abbr={Innovation},
  title = {Toward more economical large-scale foundation models: No longer a game for the few},
  journal = {The Innovation},
  volume = {6},
  number = {4},
  pages = {100832},
  year = {2025},
  month= apr,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2025.100832},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675825000359},
  author = {Yiqing Wu and Zhao Zhang* and Fei Wang and Yongjun Xu* and Jincai Huang},
  google_scholar_id={eflP2zaiRacC},
  selected={false}
}



@article{Zhou_Wei_Cao_Wang_2025, 
  bibtex_show={true},
  abbr={AAAI},
  title={Editing Memories Through Few Targeted Neurons}, 
  volume={39}, 
  url={https://ojs.aaai.org/index.php/AAAI/article/view/34807}, 
  DOI={10.1609/aaai.v39i24.34807}, 
  abstractN={Model editing is a novel research topic in large language models (LLMs), aimed at efficiently handling various knowledge editing tasks. Since irrelevant knowledge is difficult to measure,existing editing methods often lack explicit ways to preserve it, especially for editing methods based on the fine-tuning paradigm. They generally control the locality performance of model editing by constraining the range of changes in model parameters. However, their performance improvements are not always ideal, and may even lead to a decrease in the editing reliability. In this paper, we try to explore effective editing locality control methods based on the relationship between the stored knowledge and the strongly associated model components. Based on the discovery of ``knowledge neurons’’ and enough experimental results, we further explore the potential characteristics between knowledge and model components, confirm and point out: (1) only 1% neurons have significant contributions to specific knowledge storage, and (2) these targeted neurons often have a high overlap for knowledge with similar relational descriptions, which means that knowledge with similar relationships may be severely affected when these targeted neurons are modified. Based on these findings, we propose Targeted Neurons Fine-tuning with Data Augmentation (TNF-DA), which performs data augmentation based on the relational representation of edited knowledge to improve editing locality. By freezing most of the model parameters and only fine-tuning the highly contributing neurons corresponding to the edited knowledge, we obtain desirable results in terms of generalization and specificity compared with previous fine-tuning-based methods. Extensive experiments have demonstrated the superior editing performance achieved by our proposed method.}, 
  number={24}, 
  journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
  author={Zhou, Wei and Wei, Wei and Cao, Guibang and Wang, Fei}, 
  year={2025}, 
  month=Apr, 
  pages={26111-26119},
  google_scholar_id={BrmTIyaxlBUC},
  selected={false}
}

@article{Feng_Qin_Yang_An_Huang_Diao_Wang_Tao_Xu_Magno_2025, 
  bibtex_show={true},
  abbr={AAAI},
  title={MPQ-DM: Mixed Precision Quantization for Extremely Low Bit Diffusion Models}, 
  volume={39}, 
  url={https://ojs.aaai.org/index.php/AAAI/article/view/33823}, 
  DOI={10.1609/aaai.v39i16.33823}, 
  abstract={Diffusion models have received wide attention in generation tasks. However, the expensive computation cost prevents the application of diffusion models in resource-constrained scenarios. Quantization emerges as a practical solution that significantly saves storage and computation by reducing the bit-width of parameters. However, the existing quantization methods for diffusion models still cause severe degradation in performance, especially under extremely low bit-widths (2-4 bit). The primary decrease in performance comes from the significant discretization of activation values at low bit quantization. Too few activation candidates are unfriendly for outlier significant weight channel quantization, and the discretized features prevent stable learning over different time steps of the diffusion model. This paper presents MPQ-DM, a Mixed-Precision Quantization method for Diffusion Models. The proposed MPQ-DM mainly relies on two techniques: (1) To mitigate the quantization error caused by outlier severe weight channels, we propose an Outlier-Driven Mixed Quantization (OMQ) technique that uses Kurtosis to quantify outlier salient channels and apply optimized intra-layer mixed-precision bit-width allocation to recover accuracy performance within target efficiency. (2) To robustly learn representations crossing time steps, we construct a Time-Smoothed Relation Distillation (TRD) scheme between the quantized diffusion model and its full-precision counterpart, transferring discrete and continuous latent to a unified relation space to reduce the representation inconsistency. Comprehensive experiments demonstrate that MPQ-DM achieves significant accuracy gains under extremely low bit-widths compared with SOTA quantization methods. MPQ-DM achieves a 58% FID decrease under W2A4 setting compared with baseline, while all other methods even collapse.}, number={16}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Feng, Weilun and Qin, Haotong and Yang, Chuanguang and An, Zhulin and Huang, Libo and Diao, Boyu and Wang, Fei and Tao, Renshuai and Xu, Yongjun and Magno, Michele}, 
  year={2025}, 
  month=Apr, 
  pages={16595-16603}, 
  google_scholar_id={5Ul4iDaHHb8C},
  selected={false}
}


@Article{JCST-2212-13013,
  bibtex_show={true},
  abbr={JCST},
  title = {A Model-Agnostic Hierarchical Framework Towards Trajectory Prediction},
  journal = {Journal of Computer Science and Technology},
  volume = {40},
  number = {2},
  pages = {322-339},
  year = {2025},
  month=may,
  issn = {1000-9000(Print) /1860-4749(Online)},
  doi = {10.1007/s11390-023-3013-4},	
  url = {https://jcst.ict.ac.cn/en/article/doi/10.1007/s11390-023-3013-4},
  author = {Tang-Wen Qian and Yuan Wang and Yong-Jun Xu and Zhao Zhang and Lin Wu and Qiang Qiu and Fei Wang*},
  abstract = {<p>Predicting the future trajectories of multiple agents is essential for various applications in real life, such as surveillance systems, autonomous driving, and social robots. The trajectory prediction task is influenced by many factors, including the individual historical trajectory, interactions between agents, and the fuzzy nature of the observed agents’ motion. While existing methods have made great progress on the topic of trajectory prediction, they treat all the information uniformly, which limits the effectiveness of information utilization. To this end, in this paper, we propose and utilize a model-agnostic framework to regard all the information in a two-level hierarchical view. Particularly, the first-level view is the inter-trajectory view. In this level, we observe that the difficulty in predicting different trajectory samples varies. We define trajectory difficulty and train the proposed framework in an “easy-to-hard” schema. The second-level view is the intra-trajectory level. We find the influencing factors for a particular trajectory can be divided into two parts. The first part is global features, which keep stable within a trajectory, i.e., the expected destination. The second part is local features, which change over time, i.e., the current position. We believe that the two types of information should be handled in different ways. The hierarchical view is beneficial to take full advantage of the information in a fine-grained way. Experimental results validate the effectiveness of the proposed model-agnostic framework.</p>},
  google_scholar_id={HDshCWvjkbEC},
  selected={true}
}


@ARTICLE{10981648,
  bibtex_show={true},
  abbr={TKDE},
  author={Guan, Zhanpeng and Zhang, Fuwei and Zhang, Zhao and Zhuang, Fuzhen and Wang, Fei and An, Zhulin and Xu, Yongjun},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={AdaE: Knowledge Graph Embedding with Adaptive Embedding Sizes}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  keywords={Knowledge graphs;Adaptation models;Training;Data models;Search problems;Vectors;Overfitting;Tail;Optimization;Tensors;Knowledge graph embedding;Data imbalance issue;Dimension selection},
  doi={10.1109/TKDE.2025.3566270},
  google_scholar_id={q3oQSFYPqjQC},
  selected={false}
  }



@ARTICLE{11002729,
  bibtex_show={true},
  abbr={TKDE},
  author={Yu, Chengqing and Wang*, Fei and Shao, Zezhi and Qian, Tangwen and Zhang, Zhao and Wei, Wei and An, Zhulin and Wang, Qi and Xu, Yongjun},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={GinAR+: A Robust End-To-End Framework for Multivariate Time Series Forecasting with Missing Values}, 
  year={2025},
  month=may,
  volume={},
  number={},
  pages={1-14},
  keywords={Correlation;Predictive models;Forecasting;Time series analysis;Data models;Robustness;Adaptation models;Imputation;Contrastive learning;Training;Contrastive learning;Graph interpolation attention recursive network;Multivariate Time Series Forecasting with Missing Values},
  doi={10.1109/TKDE.2025.3569649},
  google_scholar_id={XiVPGOgt02cC},
  selected={true}
}


@article{HUANG2025100948,
  bibtex_show={true},
  abbr={Innovation},
  title = {Foundation models and intelligent decision-making: Progress, challenges, and perspectives},
  journal = {The Innovation},
  volume = {6},
  number = {6},
  pages = {100948},
  year = {2025},
  month = jun,
  issn = {2666-6758},
  doi = {https://doi.org/10.1016/j.xinn.2025.100948},
  url = {https://www.sciencedirect.com/science/article/pii/S2666675825001511},
  author = {Jincai Huang+ and Yongjun Xu+ and Qi Wang+ and Qi (Cheems) Wang+ and Xingxing Liang+ and Fei Wang+ and Zhao Zhang+ and Wei Wei+ and Boxuan Zhang+ and Libo Huang+ and Jingru Chang+ and Liantao Ma+ and Ting Ma+ and Yuxuan Liang+ and Jie Zhang+ and Jian Guo+ and Xuhui Jiang+ and Xinxin Fan+ and Zhulin An+ and Tingting Li+ and Xuefei Li and Zezhi Shao and Tangwen Qian and Tao Sun and Boyu Diao and Chuanguang Yang and Chenqing Yu and Yiqing Wu and Mengxian Li and Haifeng Zhang and Yongcheng Zeng and Zhicheng Zhang and Zhengqiu Zhu and Yiqin Lv and Aming Li and Xu Chen and Bo An and Wei Xiao and Chenguang Bai and Yuxing Mao and Zhigang Yin and Sheng Gui and Wentao Su and Yinghao Zhu and Junyi Gao and Xinyu He and Yizhou Li and Guangyin Jin and Xiang Ao and Xuehao Zhai and Haoran Tan and Lijun Yun and Hongquan Shi and Jun Li and Changjun Fan and Kuihua Huang and Ewen Harrison and Victor C.M. Leung and Sihang Qiu and Yanjie Dong and Xiaolong Zheng and Gang Wang and Yu Zheng and Yuanzhuo Wang and Jiafeng Guo and Lizhe Wang and Xueqi Cheng and Yaonan Wang and Shanlin Yang and Mengyin Fu and Aiguo Fei},
  keywords = {artificial intelligence, intelligent decision-making, foundation models, agent, large language model},
  abstract = {Intelligent decision-making (IDM) is a cornerstone of artificial intelligence (AI) designed to automate or augment decision processes. Modern IDM paradigms integrate advanced frameworks to enable intelligent agents to make effective and adaptive choices and decompose complex tasks into manageable steps, such as AI agents and high-level reinforcement learning. Recent advances in multimodal foundation-based approaches unify diverse input modalities—such as vision, language, and sensory data—into a cohesive decision-making process. Foundation models (FMs) have become pivotal in science and industry, transforming decision-making and research capabilities. Their large-scale, multimodal data-processing abilities foster adaptability and interdisciplinary breakthroughs across fields such as healthcare, life sciences, and education. This survey examines IDM’s evolution, advanced paradigms with FMs and their transformative impact on decision-making across diverse scientific and industrial domains, highlighting the challenges and opportunities in building efficient, adaptive, and ethical decision systems.},
  google_scholar_id={mvPsJ3kp5DgC},
  selected={true}
}


