<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Fei Wang 王飞 </title> <meta name="author" content="Fei Wang"> <meta name="description" content="Homepage for Fei Wang. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/gc-zip.png?50a8d5a5c3e3c87ca1656fd622e30bcd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://finleywang.github.io/publications/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Fei Wang 王飞 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> * denotes corresponding author and † indicates equal contribution. <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>TKDE</div> </abbr> </div> <div id="10726722" class="col-sm-8"> <div class="title">Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis</div> <div class="author"> Zezhi Shao, <em>Fei Wang<sup>*</sup></em>, Yongjun Xu<sup>*</sup>, Wei Wei, Chengqing Yu, Zhao Zhang, Di Yao, Tao Sun, Guangyin Jin, Xin Cao, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Gao Cong, Christian S. Jensen, Xueqi Cheng&lt;sup&gt;*&lt;/sup&gt;' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Knowledge and Data Engineering</em>, Jan 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">ESI Highly Cited Papers | Acquired 1.3k+ Stars at Github</a> <a href="https://doi.org/10.1109/TKDE.2024.3484454" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2024_TKDE_BasicTS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/GestaltCogTeam/BasicTS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:eJXPG6dFmWUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-175-4285F4?logo=googlescholar&amp;labelColor=beige" alt="175 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p><strong>BasicTS+ has entered ESI Highly Cited Papers and acquired 1.3k+ Stars</strong> 2025 <em>for the First, one of the Most Popular, fair and scalable benchmark of timeseries forecasting</em></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10726722</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Zezhi and Wang, Fei and Xu, Yongjun and Wei, Wei and Yu, Chengqing and Zhang, Zhao and Yao, Di and Sun, Tao and Jin, Guangyin and Cao, Xin and Cong, Gao and Jensen, Christian S. and Cheng, Xueqi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Knowledge and Data Engineering}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{291-305}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Forecasting;Time series analysis;Benchmark testing;Transformers;Predictive models;Data models;Computer science;Reliability;Proposals;Electricity;Benchmarking;multivariate time series;spatial-temporal forecasting;long-term time series forecasting}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TKDE.2024.3484454}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Information Fusion</div> </abbr> </div> <div id="YU2025102607" class="col-sm-8"> <div class="title">MGSFformer: A Multi-Granularity Spatiotemporal Fusion Transformer for air quality prediction</div> <div class="author"> Chengqing Yu, <em>Fei Wang<sup>*</sup></em>, Yilun Wang, Zezhi Shao, Tao Sun, Di Yao, and Yongjun Xu<sup>*</sup> </div> <div class="periodical"> <em>Information Fusion</em>, Jan 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.inffus.2024.102607" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:isC4tDSrTZIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-48-4285F4?logo=googlescholar&amp;labelColor=beige" alt="48 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Air quality spatiotemporal prediction can provide technical support for environmental governance and sustainable city development. As a classic multi-source spatiotemporal data, effective multi-source information fusion is key to achieving accurate air quality predictions. However, due to not fully fusing two pieces of information, classical deep learning models struggle to achieve satisfactory prediction results: (1) Multi-granularity: each air monitoring station collects air quality data at different sampling intervals, which show distinct time series patterns. (2) Spatiotemporal correlation: due to human activities and atmospheric diffusion, there exist correlations between air quality data from different air monitoring stations, necessitating the consideration of other air monitoring stations’ influences when modeling each air quality time series. In this study, to achieve satisfactory prediction results, we propose the Multi-Granularity Spatiotemporal Fusion Transformer, comprised of the residual de-redundant block, spatiotemporal attention block, and dynamic fusion block. Specifically, the residual de-redundant block eliminates information redundancy between data with different granularities and prevents the model from being misled by redundant information. The spatiotemporal attention block captures the spatiotemporal correlation of air quality data and facilitates prediction modeling. The dynamic fusion block evaluates the importance of data with different granularities and integrates the prediction results. Experimental results demonstrate that the proposed model surpasses 11 baselines by 5% in performance on three real-world datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">YU2025102607</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MGSFformer: A Multi-Granularity Spatiotemporal Fusion Transformer for air quality prediction}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Information Fusion}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{113}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102607}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1566-2535}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.inffus.2024.102607}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1566253524003853}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Chengqing and Wang, Fei and Wang, Yilun and Shao, Zezhi and Sun, Tao and Yao, Di and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Air quality prediction, Multi-Granularity Spatiotemporal Fusion Transformer, Spatiotemporal correlation, Multi-source information fusion}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>PR</div> </abbr> </div> <div id="LI2025110978" class="col-sm-8"> <div class="title">Trajectory-User Linking via Multi-Scale Graph Attention Network</div> <div class="author"> Yujie Li, Tao Sun, Zezhi Shao, Yiqiang Zhen, Yongjun Xu, and <em>Fei Wang<sup>*</sup></em> </div> <div class="periodical"> <em>Pattern Recognition</em>, Feb 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.patcog.2024.110978" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:M3NEmzRMIkIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Trajectory-User Linking (TUL) aims to link anonymous trajectories to their owners, which is considered an essential task in discovering human mobility patterns. Although existing TUL studies have shown promising results, they still have specific defects in the perception of spatio-temporal properties of trajectories, which manifested in the following three problems: missing context of the original trajectory, ignorance of spatial information, and high computational complexity. To address those issues, we revisit the characteristics of the trajectory and propose a novel model called TULMGAT (TUL via Multi-Scale Graph Attention Network) based on masked self-attention graph neural networks. Specifically, TULMGAT consists of four components: construction of check-in oriented graphs, node embedding, trajectory embedding, and trajectory user linking. Sufficient experiments on two publicly available datasets have shown that TULMGAT is the state-of-the-art model in task TUL compared to the baselines with an improvement of about 8% in accuracy and only a quarter of the fastest baseline in runtime. Furthermore, model validity experiments have verified the role of each module.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LI2025110978</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Trajectory-User Linking via Multi-Scale Graph Attention Network}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Pattern Recognition}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{158}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{110978}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0031-3203}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.patcog.2024.110978}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0031320324007295}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Yujie and Sun, Tao and Shao, Zezhi and Zhen, Yiqiang and Xu, Yongjun and Wang, Fei}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Trajectory-user linking, Graph neural network, Trajectory classification, Spatio-temporal data mining, Check-in data}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="ZHANG2025100775" class="col-sm-8"> <div class="title">MetaCity: Data-driven sustainable development of complex cities</div> <div class="author"> Yunke Zhang, Yuming Lin, Guanjie Zheng, Yu Liu, Nicholas Sukiennik, Fengli Xu, Yongjun Xu, Feng Lu, Qi Wang, Yuan Lai, and <span class="more-authors" title="click to view 9 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '9 more authors' ? 'Li Tian, Nan Li, Dongping Fang, Fei Wang&lt;sup&gt;*&lt;/sup&gt;, Tao Zhou&lt;sup&gt;*&lt;/sup&gt;, Yong Li&lt;sup&gt;*&lt;/sup&gt;, Yu Zheng, Zhiqiang Wu, Huadong Guo' : '9 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">9 more authors</span> </div> <div class="periodical"> <em>The Innovation</em>, Feb 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2024.100775" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:VOx2b1Wkg3QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-12-4285F4?logo=googlescholar&amp;labelColor=beige" alt="12 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Cities are complex systems that develop under complicated interactions among their human and environmental components. Urbanization generates substantial outcomes and opportunities while raising challenges including congestion, air pollution, inequality, etc., calling for efficient and reasonable solutions to sustainable developments. Fortunately, booming technologies generate large-scale data of complex cities, providing a chance to propose data-driven solutions for sustainable urban developments. This paper provides a comprehensive overview of data-driven urban sustainability practice. In this review article, we conceptualize MetaCity, a general framework for optimizing resource usage and allocation problems in complex cities with data-driven approaches. Under this framework, we decompose specific urban sustainable goals, e.g., efficiency and resilience, review practical urban problems under these goals, and explore the probability of using data-driven technologies as potential solutions to the challenge of complexity. On the basis of extensive urban data, we integrate urban problem discovery, operation of urban systems simulation, and complex decision-making problem solving into an entire cohesive framework to achieve sustainable development goals by optimizing resource allocation problems in complex cities.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ZHANG2025100775</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MetaCity: Data-driven sustainable development of complex cities}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100775}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2024.100775}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675824002133}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yunke and Lin, Yuming and Zheng, Guanjie and Liu, Yu and Sukiennik, Nicholas and Xu, Fengli and Xu, Yongjun and Lu, Feng and Wang, Qi and Lai, Yuan and Tian, Li and Li, Nan and Fang, Dongping and Wang, Fei and Zhou, Tao and Li, Yong and Zheng, Yu and Wu, Zhiqiang and Guo, Huadong}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{urban complex systems, sustainable development, data-driven methods, artificial intelligence}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="SHAO2025100763" class="col-sm-8"> <div class="title">Spatial-temporal large models: A super hub linking multiple scientific areas with artificial intelligence</div> <div class="author"> Zezhi Shao, Tangwen Qian, Tao Sun, <em>Fei Wang<sup>*</sup></em>, and Yongjun Xu<sup>*</sup> </div> <div class="periodical"> <em>The Innovation</em>, Feb 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2024.100763" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:8AbLer7MMksC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SHAO2025100763</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Spatial-temporal large models: A super hub linking multiple scientific areas with artificial intelligence}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100763}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2024.100763}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675824002017}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Zezhi and Qian, Tangwen and Sun, Tao and Wang, Fei and Xu, Yongjun}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="CHEN2025100780" class="col-sm-8"> <div class="title">Toward the robustness of autonomous vehicles in the AI era</div> <div class="author"> Siheng Chen<sup>*</sup>, Yiyi Liao<sup>*</sup>, <em>Fei Wang<sup>*</sup></em>, Gang Wang<sup>*</sup>, Liang Wang<sup>*</sup>, Yafei Wang<sup>*</sup>, and Xichan Zhu<sup>*</sup> </div> <div class="periodical"> <em>The Innovation</em>, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2024.100780" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:LPZeul_q3PIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CHEN2025100780</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Toward the robustness of autonomous vehicles in the AI era}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100780}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2024.100780}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675824002182}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Siheng and Liao, Yiyi and Wang, Fei and Wang, Gang and Wang, Liang and Wang, Yafei and Zhu, Xichan}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="WU2025100832" class="col-sm-8"> <div class="title">Toward more economical large-scale foundation models: No longer a game for the few</div> <div class="author"> Yiqing Wu, Zhao Zhang<sup>*</sup>, <em>Fei Wang</em>, Yongjun Xu<sup>*</sup>, and Jincai Huang </div> <div class="periodical"> <em>The Innovation</em>, Apr 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2025.100832" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:eflP2zaiRacC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WU2025100832</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Toward more economical large-scale foundation models: No longer a game for the few}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100832}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2025.100832}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675825000359}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Yiqing and Zhang, Zhao and Wang, Fei and Xu, Yongjun and Huang, Jincai}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> </div> <div id="Zhou_Wei_Cao_Wang_2025" class="col-sm-8"> <div class="title">Editing Memories Through Few Targeted Neurons</div> <div class="author"> Wei Zhou, Wei Wei, Guibang Cao, and <em>Fei Wang</em> </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, Apr 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1609/aaai.v39i24.34807" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:BrmTIyaxlBUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Zhou_Wei_Cao_Wang_2025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Editing Memories Through Few Targeted Neurons}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{39}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/34807}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1609/aaai.v39i24.34807}</span><span class="p">,</span>
  <span class="na">abstractn</span> <span class="p">=</span> <span class="s">{Model editing is a novel research topic in large language models (LLMs), aimed at efficiently handling various knowledge editing tasks. Since irrelevant knowledge is difficult to measure,existing editing methods often lack explicit ways to preserve it, especially for editing methods based on the fine-tuning paradigm. They generally control the locality performance of model editing by constraining the range of changes in model parameters. However, their performance improvements are not always ideal, and may even lead to a decrease in the editing reliability. In this paper, we try to explore effective editing locality control methods based on the relationship between the stored knowledge and the strongly associated model components. Based on the discovery of ``knowledge neurons’’ and enough experimental results, we further explore the potential characteristics between knowledge and model components, confirm and point out: (1) only 1% neurons have significant contributions to specific knowledge storage, and (2) these targeted neurons often have a high overlap for knowledge with similar relational descriptions, which means that knowledge with similar relationships may be severely affected when these targeted neurons are modified. Based on these findings, we propose Targeted Neurons Fine-tuning with Data Augmentation (TNF-DA), which performs data augmentation based on the relational representation of edited knowledge to improve editing locality. By freezing most of the model parameters and only fine-tuning the highly contributing neurons corresponding to the edited knowledge, we obtain desirable results in terms of generalization and specificity compared with previous fine-tuning-based methods. Extensive experiments have demonstrated the superior editing performance achieved by our proposed method.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Wei and Wei, Wei and Cao, Guibang and Wang, Fei}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{26111-26119}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> </div> <div id="Feng_Qin_Yang_An_Huang_Diao_Wang_Tao_Xu_Magno_2025" class="col-sm-8"> <div class="title">MPQ-DM: Mixed Precision Quantization for Extremely Low Bit Diffusion Models</div> <div class="author"> Weilun Feng, Haotong Qin, Chuanguang Yang, Zhulin An, Libo Huang, Boyu Diao, <em>Fei Wang</em>, Renshuai Tao, Yongjun Xu, and Michele Magno </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, Apr 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1609/aaai.v39i16.33823" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:5Ul4iDaHHb8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-9-4285F4?logo=googlescholar&amp;labelColor=beige" alt="9 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Diffusion models have received wide attention in generation tasks. However, the expensive computation cost prevents the application of diffusion models in resource-constrained scenarios. Quantization emerges as a practical solution that significantly saves storage and computation by reducing the bit-width of parameters. However, the existing quantization methods for diffusion models still cause severe degradation in performance, especially under extremely low bit-widths (2-4 bit). The primary decrease in performance comes from the significant discretization of activation values at low bit quantization. Too few activation candidates are unfriendly for outlier significant weight channel quantization, and the discretized features prevent stable learning over different time steps of the diffusion model. This paper presents MPQ-DM, a Mixed-Precision Quantization method for Diffusion Models. The proposed MPQ-DM mainly relies on two techniques: (1) To mitigate the quantization error caused by outlier severe weight channels, we propose an Outlier-Driven Mixed Quantization (OMQ) technique that uses Kurtosis to quantify outlier salient channels and apply optimized intra-layer mixed-precision bit-width allocation to recover accuracy performance within target efficiency. (2) To robustly learn representations crossing time steps, we construct a Time-Smoothed Relation Distillation (TRD) scheme between the quantized diffusion model and its full-precision counterpart, transferring discrete and continuous latent to a unified relation space to reduce the representation inconsistency. Comprehensive experiments demonstrate that MPQ-DM achieves significant accuracy gains under extremely low bit-widths compared with SOTA quantization methods. MPQ-DM achieves a 58% FID decrease under W2A4 setting compared with baseline, while all other methods even collapse.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Feng_Qin_Yang_An_Huang_Diao_Wang_Tao_Xu_Magno_2025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MPQ-DM: Mixed Precision Quantization for Extremely Low Bit Diffusion Models}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{39}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/33823}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1609/aaai.v39i16.33823}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Weilun and Qin, Haotong and Yang, Chuanguang and An, Zhulin and Huang, Libo and Diao, Boyu and Wang, Fei and Tao, Renshuai and Xu, Yongjun and Magno, Michele}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{16595-16603}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>JCST</div> </abbr> </div> <div id="JCST-2212-13013" class="col-sm-8"> <div class="title">A Model-Agnostic Hierarchical Framework Towards Trajectory Prediction</div> <div class="author"> Tang-Wen Qian, Yuan Wang, Yong-Jun Xu, Zhao Zhang, Lin Wu, Qiang Qiu, and <em>Fei Wang<sup>*</sup></em> </div> <div class="periodical"> <em>Journal of Computer Science and Technology</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s11390-023-3013-4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:HDshCWvjkbEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p></p> <p>Predicting the future trajectories of multiple agents is essential for various applications in real life, such as surveillance systems, autonomous driving, and social robots. The trajectory prediction task is influenced by many factors, including the individual historical trajectory, interactions between agents, and the fuzzy nature of the observed agents’ motion. While existing methods have made great progress on the topic of trajectory prediction, they treat all the information uniformly, which limits the effectiveness of information utilization. To this end, in this paper, we propose and utilize a model-agnostic framework to regard all the information in a two-level hierarchical view. Particularly, the first-level view is the inter-trajectory view. In this level, we observe that the difficulty in predicting different trajectory samples varies. We define trajectory difficulty and train the proposed framework in an “easy-to-hard” schema. The second-level view is the intra-trajectory level. We find the influencing factors for a particular trajectory can be divided into two parts. The first part is global features, which keep stable within a trajectory, i.e., the expected destination. The second part is local features, which change over time, i.e., the current position. We believe that the two types of information should be handled in different ways. The hierarchical view is beneficial to take full advantage of the information in a fine-grained way. Experimental results validate the effectiveness of the proposed model-agnostic framework.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">JCST-2212-13013</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Model-Agnostic Hierarchical Framework Towards Trajectory Prediction}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Computer Science and Technology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{40}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{322-339}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1000-9000(Print) /1860-4749(Online)}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s11390-023-3013-4}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://jcst.ict.ac.cn/en/article/doi/10.1007/s11390-023-3013-4}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qian, Tang-Wen and Wang, Yuan and Xu, Yong-Jun and Zhang, Zhao and Wu, Lin and Qiu, Qiang and Wang, Fei}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>TKDE</div> </abbr> </div> <div id="10981648" class="col-sm-8"> <div class="title">AdaE: Knowledge Graph Embedding with Adaptive Embedding Sizes</div> <div class="author"> Zhanpeng Guan, Fuwei Zhang, Zhao Zhang, Fuzhen Zhuang, <em>Fei Wang</em>, Zhulin An, and Yongjun Xu </div> <div class="periodical"> <em>IEEE Transactions on Knowledge and Data Engineering</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TKDE.2025.3566270" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:q3oQSFYPqjQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10981648</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guan, Zhanpeng and Zhang, Fuwei and Zhang, Zhao and Zhuang, Fuzhen and Wang, Fei and An, Zhulin and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Knowledge and Data Engineering}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AdaE: Knowledge Graph Embedding with Adaptive Embedding Sizes}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-14}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Knowledge graphs;Adaptation models;Training;Data models;Search problems;Vectors;Overfitting;Tail;Optimization;Tensors;Knowledge graph embedding;Data imbalance issue;Dimension selection}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TKDE.2025.3566270}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>TKDE</div> </abbr> </div> <div id="11002729" class="col-sm-8"> <div class="title">GinAR+: A Robust End-To-End Framework for Multivariate Time Series Forecasting with Missing Values</div> <div class="author"> Chengqing Yu, <em>Fei Wang<sup>*</sup></em>, Zezhi Shao, Tangwen Qian, Zhao Zhang, Wei Wei, Zhulin An, Qi Wang, and Yongjun Xu </div> <div class="periodical"> <em>IEEE Transactions on Knowledge and Data Engineering</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TKDE.2025.3569649" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:XiVPGOgt02cC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-14-4285F4?logo=googlescholar&amp;labelColor=beige" alt="14 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">11002729</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Chengqing and Wang, Fei and Shao, Zezhi and Qian, Tangwen and Zhang, Zhao and Wei, Wei and An, Zhulin and Wang, Qi and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Knowledge and Data Engineering}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GinAR+: A Robust End-To-End Framework for Multivariate Time Series Forecasting with Missing Values}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-14}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Correlation;Predictive models;Forecasting;Time series analysis;Data models;Robustness;Adaptation models;Imputation;Contrastive learning;Training;Contrastive learning;Graph interpolation attention recursive network;Multivariate Time Series Forecasting with Missing Values}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TKDE.2025.3569649}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="HUANG2025100948" class="col-sm-8"> <div class="title">Foundation models and intelligent decision-making: Progress, challenges, and perspectives</div> <div class="author"> Jincai Huang<sup>†</sup>, Yongjun Xu<sup>†</sup>, Qi Wang<sup>†</sup>, Qi (Cheems) Wang<sup>†</sup>, Xingxing Liang<sup>†</sup>, <em>Fei Wang<sup>†</sup></em>, Zhao Zhang<sup>†</sup>, Wei Wei<sup>†</sup>, Boxuan Zhang<sup>†</sup>, Libo Huang<sup>†</sup>, and <span class="more-authors" title="click to view 61 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '61 more authors' ? 'Jingru Chang&lt;sup&gt;†&lt;/sup&gt;, Liantao Ma&lt;sup&gt;†&lt;/sup&gt;, Ting Ma&lt;sup&gt;†&lt;/sup&gt;, Yuxuan Liang&lt;sup&gt;†&lt;/sup&gt;, Jie Zhang&lt;sup&gt;†&lt;/sup&gt;, Jian Guo&lt;sup&gt;†&lt;/sup&gt;, Xuhui Jiang&lt;sup&gt;†&lt;/sup&gt;, Xinxin Fan&lt;sup&gt;†&lt;/sup&gt;, Zhulin An&lt;sup&gt;†&lt;/sup&gt;, Tingting Li&lt;sup&gt;†&lt;/sup&gt;, Xuefei Li, Zezhi Shao, Tangwen Qian, Tao Sun, Boyu Diao, Chuanguang Yang, Chenqing Yu, Yiqing Wu, Mengxian Li, Haifeng Zhang, Yongcheng Zeng, Zhicheng Zhang, Zhengqiu Zhu, Yiqin Lv, Aming Li, Xu Chen, Bo An, Wei Xiao, Chenguang Bai, Yuxing Mao, Zhigang Yin, Sheng Gui, Wentao Su, Yinghao Zhu, Junyi Gao, Xinyu He, Yizhou Li, Guangyin Jin, Xiang Ao, Xuehao Zhai, Haoran Tan, Lijun Yun, Hongquan Shi, Jun Li, Changjun Fan, Kuihua Huang, Ewen Harrison, Victor C.M. Leung, Sihang Qiu, Yanjie Dong, Xiaolong Zheng, Gang Wang, Yu Zheng, Yuanzhuo Wang, Jiafeng Guo, Lizhe Wang, Xueqi Cheng, Yaonan Wang, Shanlin Yang, Mengyin Fu, Aiguo Fei' : '61 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">61 more authors</span> </div> <div class="periodical"> <em>The Innovation</em>, Jun 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2025.100948" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2025_Innovation_IDM_Review.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:mvPsJ3kp5DgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-15-4285F4?logo=googlescholar&amp;labelColor=beige" alt="15 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Intelligent decision-making (IDM) is a cornerstone of artificial intelligence (AI) designed to automate or augment decision processes. Modern IDM paradigms integrate advanced frameworks to enable intelligent agents to make effective and adaptive choices and decompose complex tasks into manageable steps, such as AI agents and high-level reinforcement learning. Recent advances in multimodal foundation-based approaches unify diverse input modalities—such as vision, language, and sensory data—into a cohesive decision-making process. Foundation models (FMs) have become pivotal in science and industry, transforming decision-making and research capabilities. Their large-scale, multimodal data-processing abilities foster adaptability and interdisciplinary breakthroughs across fields such as healthcare, life sciences, and education. This survey examines IDM’s evolution, advanced paradigms with FMs and their transformative impact on decision-making across diverse scientific and industrial domains, highlighting the challenges and opportunities in building efficient, adaptive, and ethical decision systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">HUANG2025100948</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Foundation models and intelligent decision-making: Progress, challenges, and perspectives}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100948}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2025.100948}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675825001511}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Jincai and Xu, Yongjun and Wang, Qi and Wang, Qi (Cheems) and Liang, Xingxing and Wang, Fei and Zhang, Zhao and Wei, Wei and Zhang, Boxuan and Huang, Libo and Chang, Jingru and Ma, Liantao and Ma, Ting and Liang, Yuxuan and Zhang, Jie and Guo, Jian and Jiang, Xuhui and Fan, Xinxin and An, Zhulin and Li, Tingting and Li, Xuefei and Shao, Zezhi and Qian, Tangwen and Sun, Tao and Diao, Boyu and Yang, Chuanguang and Yu, Chenqing and Wu, Yiqing and Li, Mengxian and Zhang, Haifeng and Zeng, Yongcheng and Zhang, Zhicheng and Zhu, Zhengqiu and Lv, Yiqin and Li, Aming and Chen, Xu and An, Bo and Xiao, Wei and Bai, Chenguang and Mao, Yuxing and Yin, Zhigang and Gui, Sheng and Su, Wentao and Zhu, Yinghao and Gao, Junyi and He, Xinyu and Li, Yizhou and Jin, Guangyin and Ao, Xiang and Zhai, Xuehao and Tan, Haoran and Yun, Lijun and Shi, Hongquan and Li, Jun and Fan, Changjun and Huang, Kuihua and Harrison, Ewen and Leung, Victor C.M. and Qiu, Sihang and Dong, Yanjie and Zheng, Xiaolong and Wang, Gang and Zheng, Yu and Wang, Yuanzhuo and Guo, Jiafeng and Wang, Lizhe and Cheng, Xueqi and Wang, Yaonan and Yang, Shanlin and Fu, Mengyin and Fei, Aiguo}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{artificial intelligence, intelligent decision-making, foundation models, agent, large language model}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">KDD</abbr> </div> <div id="blast" class="col-sm-8"> <div class="title">BLAST: Balanced Sampling Time Series Corpus for Universal Forecasting Models</div> <div class="author"> Zezhi Shao, Yujie Li, <em>Fei Wang<sup>*</sup></em>, Chengqing Yu, Yisong Fu, Tangwen Qian, Bin Xu, Boyu Diao, Yongjun Xu, and Xueqi Cheng </div> <div class="periodical"> <em>In Proceedings of the 31th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, Toronton, ON, Canada, Aug 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2025_2505.17871v2-BLAST.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/GestaltCogTeam/BLAST" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:t6usbXjVLHcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The advent of universal time series forecasting models has revolutionized zero-shot forecasting across diverse domains, yet the critical role of data diversity in training these models remains underexplored. Existing large-scale time series datasets often suffer from inherent biases and imbalanced distributions, leading to suboptimal model performance and generalization. To address this gap, we introduce BLAST, a novel pre-training corpus designed to enhance data diversity through a balanced sampling strategy. First, BLAST incorporates 321 billion observations from publicly available datasets and employs a comprehensive suite of statistical metrics to characterize time series patterns. Then, to facilitate pattern-oriented sampling, the data is implicitly clustered using grid-based partitioning. Furthermore, by integrating grid sampling and grid mixup techniques, BLAST ensures a balanced and representative coverage of diverse patterns. Experimental results demonstrate that models pre-trained on BLAST achieve state-of-the-art performance with a fraction of the computational resources and training tokens required by existing methods. Our findings highlight the pivotal role of data diversity in improving both training efficiency and model performance for the universal forecasting task.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">blast</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Zezhi and Li, Yujie and Wang, Fei and Yu, Chengqing and Fu, Yisong and Qian, Tangwen and Xu, Bin and Diao, Boyu and Xu, Yongjun and Cheng, Xueqi}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BLAST: Balanced Sampling Time Series Corpus for Universal Forecasting Models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 31th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{large-scale time series dataset, balanced sampling, universal time series forecasting}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Toronton, ON, Canada}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '25}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICASSP</abbr> </div> <div id="10446144" class="col-sm-8"> <div class="title">Dynamic Frequency Domain Graph Convolutional Network for Traffic Forecasting</div> <div class="author"> Yujie Li, Zezhi Shao, Yongjun Xu, Qiang Qiu, Zhaogang Cao, and <em>Fei Wang</em> </div> <div class="periodical"> <em>In ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Apr 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ICASSP48485.2024.10446144" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:4JMBOYKVnBMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-21-4285F4?logo=googlescholar&amp;labelColor=beige" alt="21 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10446144</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Yujie and Shao, Zezhi and Xu, Yongjun and Qiu, Qiang and Cao, Zhaogang and Wang, Fei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamic Frequency Domain Graph Convolutional Network for Traffic Forecasting}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5245-5249}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Convolution;Frequency-domain analysis;Time series analysis;Transportation;Traffic control;Spatial databases;Sensors;Traffic prediction;frequency domain signal processing;multivariate time series analysis;dynamic graph learning;graph convolution}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP48485.2024.10446144}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">COLING</abbr> </div> <div id="chen-etal-2024-self" class="col-sm-8"> <div class="title">Self-Improvement Programming for Temporal Knowledge Graph Question Answering</div> <div class="author"> Zhuo Chen, Zhao Zhang, Zixuan Li, <em>Fei Wang</em>, Yutao Zeng, Xiaolong Jin, and Yongjun Xu </div> <div class="periodical"> <em>In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:r0BpntZqJG4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-13-4285F4?logo=googlescholar&amp;labelColor=beige" alt="13 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Temporal Knowledge Graph Question Answering (TKGQA) aims to answer questions with temporal intent over Temporal Knowledge Graphs (TKGs). The core challenge of this task lies in understanding the complex semantic information regarding multiple types of time constraints (e.g., before, first) in questions. Existing end-to-end methods implicitly model the time constraints by learning time-aware embeddings of questions and candidate answers, which is far from understanding the question comprehensively. Motivated by semantic-parsing-based approaches that explicitly model constraints in questions by generating logical forms with symbolic operators, we design fundamental temporal operators for time constraints and introduce a novel self-improvement Programming method for TKGQA (Prog-TQA). Specifically, Prog-TQA leverages the in-context learning ability of Large Language Models (LLMs) to understand the combinatory time constraints in the questions and generate corresponding program drafts with a few examples given. Then, it aligns these drafts to TKGs with the linking module and subsequently executes them to generate the answers. To enhance the ability to understand questions, Prog-TQA is further equipped with a self-improvement strategy to effectively bootstrap LLMs using high-quality self-generated drafts. Extensive experiments demonstrate the superiority of the proposed Prog-TQA on MultiTQ and CronQuestions datasets, especially in the Hits@1 metric.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen-etal-2024-self</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Self-Improvement Programming for Temporal Knowledge Graph Question Answering}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Zhuo and Zhang, Zhao and Li, Zixuan and Wang, Fei and Zeng, Yutao and Jin, Xiaolong and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Calzolari, Nicoletta and Kan, Min-Yen and Hoste, Veronique and Lenci, Alessandro and Sakti, Sakriani and Xue, Nianwen}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Torino, Italia}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ELRA and ICCL}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.lrec-main.1270/}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{14579--14594}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICDE</abbr> </div> <div id="10598115" class="col-sm-8"> <div class="title">AdapTraj: A Multi-Source Domain Generalization Framework for Multi-Agent Trajectory Prediction</div> <div class="author"> Tangwen Qian, Yile Chen, Gao Cong, Yongjun Xu, and <em>Fei Wang<sup>*</sup></em> </div> <div class="periodical"> <em>In 2024 IEEE 40th International Conference on Data Engineering (ICDE)</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ICDE60146.2024.00113" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:j3f4tGmQtD8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-17-4285F4?logo=googlescholar&amp;labelColor=beige" alt="17 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10598115</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qian, Tangwen and Chen, Yile and Cong, Gao and Xu, Yongjun and Wang, Fei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 IEEE 40th International Conference on Data Engineering (ICDE)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AdapTraj: A Multi-Source Domain Generalization Framework for Multi-Agent Trajectory Prediction}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5048-5060}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Degradation;Adaptation models;Buildings;Predictive models;Data engineering;Data models;Trajectory;multi-agent trajectory prediction;multi-source domain generalization;distribution shift}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICDE60146.2024.00113}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">KDD</abbr> </div> <div id="10.1145/3637528.3672055" class="col-sm-8"> <div class="title">GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing</div> <div class="author"> Chengqing Yu, <em>Fei Wang<sup>*</sup></em>, Zezhi Shao, Tangwen Qian, Zhao Zhang, Wei Wei, and Yongjun Xu<sup>*</sup> </div> <div class="periodical"> <em>In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, Barcelona, Spain, Aug 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3637528.3672055" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/GestaltCogTeam/GinAR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:iH-uZ7U-co4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-47-4285F4?logo=googlescholar&amp;labelColor=beige" alt="47 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Multivariate time series forecasting (MTSF) is crucial for decision-making to precisely forecast the future values/trends, based on the complex relationships identified from historical observations of multiple sequences. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme of MTSF model as their powerful capability in mining spatial-temporal dependencies, but almost of them heavily rely on the assumption of historical data integrity. In reality, due to factors such as data collector failures and time-consuming repairment, it is extremely challenging to collect the whole historical observations without missing any variable. In this case, STGNNs can only utilize a subset of normal variables and easily suffer from the incorrect spatial-temporal dependency modeling issue, resulting in the degradation of their forecasting performance. To address the problem, in this paper, we propose a novel Graph Interpolation Attention Recursive Network (named GinAR) to precisely model the spatial-temporal dependencies over the limited collected data for forecasting. In GinAR, it consists of two key components, that is, interpolation attention and adaptive graph convolution to take place of the fully connected layer of simple recursive units, and thus are capable of recovering all missing variables and reconstructing the correct spatial-temporal dependencies for recursively modeling of multivariate time series data, respectively. Extensive experiments conducted on five real-world datasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when 90% of variables are missing, it can still accurately predict the future values of all variables.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3637528.3672055</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Chengqing and Wang, Fei and Shao, Zezhi and Qian, Tangwen and Zhang, Zhao and Wei, Wei and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400704901}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3637528.3672055}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3637528.3672055}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3989-4000}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{adaptive graph convolution, graph interpolation attention recursive network, interpolation attention, multivariate time series forecasting, variable missing}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Barcelona, Spain}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="ZHAO2024100691" class="col-sm-8"> <div class="title">Artificial intelligence for geoscience: Progress, challenges, and perspectives</div> <div class="author"> Tianjie Zhao<sup>†</sup>, Sheng Wang<sup>†</sup>, Chaojun Ouyang<sup>†</sup>, Min Chen<sup>†</sup>, Chenying Liu<sup>†</sup>, Jin Zhang<sup>†</sup>, Long Yu<sup>†</sup>, <em>Fei Wang<sup>†</sup></em>, Yong Xie<sup>†</sup>, Jun Li<sup>†</sup>, and <span class="more-authors" title="click to view 41 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '41 more authors' ? 'Fang Wang, Sabine Grunwald, Bryan M. Wong, Fan Zhang, Zhen Qian, Yongjun Xu, Chengqing Yu, Wei Han, Tao Sun, Zezhi Shao, Tangwen Qian, Zhao Chen, Jiangyuan Zeng, Huai Zhang, Husi Letu, Bing Zhang, Li Wang, Lei Luo, Chong Shi, Hongjun Su, Hongsheng Zhang, Shuai Yin, Ni Huang, Wei Zhao, Nan Li, Chaolei Zheng, Yang Zhou, Changping Huang, Defeng Feng, Qingsong Xu, Yan Wu, Danfeng Hong, Zhenyu Wang, Yinyi Lin, Tangtang Zhang, Prashant Kumar, Antonio Plaza, Jocelyn Chanussot, Jiabao Zhang, Jiancheng Shi, Lizhe Wang&lt;sup&gt;*&lt;/sup&gt;' : '41 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">41 more authors</span> </div> <div class="periodical"> <em>The Innovation</em>, Sep 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2024.100691" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2024_Innovation_AI4Geo_Review.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:maZDTaKrznsC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-294-4285F4?logo=googlescholar&amp;labelColor=beige" alt="294 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>This paper explores the evolution of geoscientific inquiry, tracing the progression from traditional physics-based models to modern data-driven approaches facilitated by significant advancements in artificial intelligence (AI) and data collection techniques. Traditional models, which are grounded in physical and numerical frameworks, provide robust explanations by explicitly reconstructing underlying physical processes. However, their limitations in comprehensively capturing Earth’s complexities and uncertainties pose challenges in optimization and real-world applicability. In contrast, contemporary data-driven models, particularly those utilizing machine learning (ML) and deep learning (DL), leverage extensive geoscience data to glean insights without requiring exhaustive theoretical knowledge. ML techniques have shown promise in addressing Earth science-related questions. Nevertheless, challenges such as data scarcity, computational demands, data privacy concerns, and the “black-box” nature of AI models hinder their seamless integration into geoscience. The integration of physics-based and data-driven methodologies into hybrid models presents an alternative paradigm. These models, which incorporate domain knowledge to guide AI methodologies, demonstrate enhanced efficiency and performance with reduced training data requirements. This review provides a comprehensive overview of geoscientific research paradigms, emphasizing untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of AI in geoscience. The paper outlines a dynamic field ripe with possibilities, poised to unlock new understandings of Earth’s complexities and further advance geoscience exploration.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ZHAO2024100691</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Artificial intelligence for geoscience: Progress, challenges, and perspectives}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100691}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2024.100691}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675824001292}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhao, Tianjie and Wang, Sheng and Ouyang, Chaojun and Chen, Min and Liu, Chenying and Zhang, Jin and Yu, Long and Wang, Fei and Xie, Yong and Li, Jun and Wang, Fang and Grunwald, Sabine and Wong, Bryan M. and Zhang, Fan and Qian, Zhen and Xu, Yongjun and Yu, Chengqing and Han, Wei and Sun, Tao and Shao, Zezhi and Qian, Tangwen and Chen, Zhao and Zeng, Jiangyuan and Zhang, Huai and Letu, Husi and Zhang, Bing and Wang, Li and Luo, Lei and Shi, Chong and Su, Hongjun and Zhang, Hongsheng and Yin, Shuai and Huang, Ni and Zhao, Wei and Li, Nan and Zheng, Chaolei and Zhou, Yang and Huang, Changping and Feng, Defeng and Xu, Qingsong and Wu, Yan and Hong, Danfeng and Wang, Zhenyu and Lin, Yinyi and Zhang, Tangtang and Kumar, Prashant and Plaza, Antonio and Chanussot, Jocelyn and Zhang, Jiabao and Shi, Jiancheng and Wang, Lizhe}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{artificial intelligence, machine learning, deep learning, geoscience}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="XU2024100725" class="col-sm-8"> <div class="title">Artificial intelligence is restructuring a new world</div> <div class="author"> Yongjun Xu<sup>*</sup>, <em>Fei Wang<sup>*</sup></em>, and Tangtang Zhang<sup>*</sup> </div> <div class="periodical"> <em>The Innovation</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2024.100725" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:XiSMed-E-HIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-17-4285F4?logo=googlescholar&amp;labelColor=beige" alt="17 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XU2024100725</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Artificial intelligence is restructuring a new world}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100725}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2024.100725}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675824001632}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Yongjun and Wang, Fei and Zhang, Tangtang}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CIKM</abbr> </div> <div id="10.1145/3583780.3614851" class="col-sm-8"> <div class="title">DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction</div> <div class="author"> Chengqing Yu, <em>Fei Wang<sup>*</sup></em>, Zezhi Shao, Tao Sun, Lin Wu, and Yongjun Xu </div> <div class="periodical"> <em>In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, Birmingham, United Kingdom, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">The 2nd-Cited paper in CIKM 2023</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3583780.3614851" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2023_CIKM_DSFormer.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/GestaltCogTeam/DSformer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:L8Ckcad2t8MC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-150-4285F4?logo=googlescholar&amp;labelColor=beige" alt="150 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p><strong>The 2nd-Most Cited paper in CIKM 2023</strong> 2023 <em>2/676</em></p> </div> <div class="abstract hidden"> <p>Multivariate time series long-term prediction, which aims to predict the change of data in a long time, can provide references for decision-making. Although transformer-based models have made progress in this field, they usually do not make full use of three features of multivariate time series: global information, local information, and variables correlation. To effectively mine the above three features and establish a high-precision prediction model, we propose a double sampling transformer (DSformer), which consists of the double sampling (DS) block and the temporal variable attention (TVA) block. Firstly, the DS block employs down sampling and piecewise sampling to transform the original series into feature vectors that focus on global information and local information respectively. Then, TVA block uses temporal attention and variable attention to mine these feature vectors from different dimensions and extract key information. Finally, based on a parallel structure, DSformer uses multiple TVA blocks to mine and integrate different features obtained from DS blocks respectively. The integrated feature information is passed to the generative decoder based on a multi-layer perceptron to realize multivariate time series long-term prediction. Experimental results on nine real-world datasets show that DSformer can outperform eight existing baselines.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3583780.3614851</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Chengqing and Wang, Fei and Shao, Zezhi and Sun, Tao and Wu, Lin and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701245}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3583780.3614851}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3583780.3614851}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3062-3072}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{double sampling transformer, multivariate time series long-term prediction, temporal variable attention block}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Birmingham, United Kingdom}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '23}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>TKDE</div> </abbr> </div> <div id="9961953" class="col-sm-8"> <div class="title">Heterogeneous Graph Neural Network With Multi-View Representation Learning</div> <div class="author"> Zezhi Shao, Yongjun Xu, Wei Wei, <em>Fei Wang</em>, Zhao Zhang, and Feida Zhu </div> <div class="periodical"> <em>IEEE Transactions on Knowledge and Data Engineering</em>, Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TKDE.2022.3224193" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:hqOjcs7Dif8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-35-4285F4?logo=googlescholar&amp;labelColor=beige" alt="35 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9961953</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Zezhi and Xu, Yongjun and Wei, Wei and Wang, Fei and Zhang, Zhao and Zhu, Feida}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Knowledge and Data Engineering}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Heterogeneous Graph Neural Network With Multi-View Representation Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11476-11488}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Semantics;Mercury (metals);Graph neural networks;Aggregates;Task analysis;Representation learning;Adaptation models;Heterogeneous graphs;graph neural networks;graph embedding}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TKDE.2022.3224193}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CIKM</abbr> </div> <div id="10.1145/3583780.3615253" class="col-sm-8"> <div class="title">Clustering-property Matters: A Cluster-aware Network for Large Scale Multivariate Time Series Forecasting</div> <div class="author"> Yuan Wang, Zezhi Shao, Tao Sun, Chengqing Yu, Yongjun Xu, and <em>Fei Wang<sup>*</sup></em> </div> <div class="periodical"> <em>In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, Birmingham, United Kingdom, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3583780.3615253" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:R3hNpaxXUhUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-9-4285F4?logo=googlescholar&amp;labelColor=beige" alt="9 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Large-scale Multivariate Time Series(MTS) widely exist in various real-world systems, imposing significant demands on model efficiency. A recent work, STID, addressed the high complexity issue of popular Spatial-Temporal Graph Neural Networks(STGNNs). Despite its success, when applied to large-scale MTS data, the number of parameters of STID for modeling spatial dependencies increases substantially, leading to over-parameterization issues and suboptimal performance. These observations motivate us to explore new approaches for modeling spatial dependencies in a parameter-friendly manner. In this paper, we argue that the spatial properties of variables are essentially the superposition of multiple cluster centers. Accordingly, we propose a Cluster-Aware Network(CANet), which effectively captures spatial dependencies by mining the implicit cluster centers of variables. CANet solely optimizes the cluster centers instead of the spatial information of all nodes, thereby significantly reducing the parameter amount. Extensive experiments on two large-scale datasets validate our motivation and demonstrate the superiority of CANet.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3583780.3615253</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Yuan and Shao, Zezhi and Sun, Tao and Yu, Chengqing and Xu, Yongjun and Wang, Fei}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Clustering-property Matters: A Cluster-aware Network for Large Scale Multivariate Time Series Forecasting}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701245}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3583780.3615253}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3583780.3615253}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4340-4344}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{multivariate time series forecasting, large-scale, cluster centers}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Birmingham, United Kingdom}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '23}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="WANG2023100405" class="col-sm-8"> <div class="title">AI-enhanced spatial-temporal data-mining technology: New chance for next-generation urban computing</div> <div class="author"> <em>Fei Wang<sup>*</sup></em>, Di Yao<sup>*</sup>, Yong Li<sup>*</sup>, Tao Sun, and Zhao Zhang </div> <div class="periodical"> <em>The Innovation</em>, Mar 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2023.100405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2024_Innovation_ST-LM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:mVmsd5A6BfQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-29-4285F4?logo=googlescholar&amp;labelColor=beige" alt="29 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WANG2023100405</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AI-enhanced spatial-temporal data-mining technology: New chance for next-generation urban computing}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100405}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2023.100405}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675823000334}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Fei and Yao, Di and Li, Yong and Sun, Tao and Zhang, Zhao}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">DASFAA</abbr> </div> <div id="10.1007/978-3-031-00126-0_33" class="col-sm-8"> <div class="title">Human Mobility Identification by Deep Behavior Relevant Location Representation</div> <div class="author"> Tao Sun, <em>Fei Wang</em>, Zhao Zhang, Lin Wu, and Yongjun Xu </div> <div class="periodical"> <em>In Database Systems for Advanced Applications</em>, Apr 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Best Student Paper Award</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2022_DASFAA.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:KlAtU1dfN6UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Fei Wang receveid the <strong>Best Student Paper Award</strong> 2022 <em>for the contribution to method of Deep Behavior Relevant Location Representation</em></p> </div> <div class="abstract hidden"> <p>This paper focuses on Trajectory User Link (TUL), which aims at identifying user identities through exploiting their mobility patterns. Existing TUL approaches are based on location representation, a way to learn location associations by embedding vectors that can indicate the level of semantic similarity between the locations. However, existing methods for location representation don’t consider the semantic diversity of locations, which will lead to a misunderstanding of the semantic information of trajectory when linking anonymous trajectories to candidate users. To solve this problem, in this paper, we propose Deep Behavior Relevant Location representation (DBRLr) to map the polysemous locations into distinct vectors, from the perspective of users’ behavior to reflect the semantic polysemy of locations. To learn this representation, we build a Location Prediction-based Movement Model (LP-based MM), which learns user behavior representation at each visited location from a large history trajectory corpora. LP-based MM considers both Continuity and Cyclicity characteristics of user’s movement. We employ the combination of the intermediate layer representation in LP-based MM as DBRLr. An effective recurrent neural network is used to link anonymous trajectories with candidate users. Experiments are conducted on two real-world datasets, and the result shows that our method performs beyond existing methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1007/978-3-031-00126-0_33</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Tao and Wang, Fei and Zhang, Zhao and Wu, Lin and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Human Mobility Identification by Deep Behavior Relevant Location Representation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Database Systems for Advanced Applications}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{439--454}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-00126-0}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">VLDB</abbr> </div> <div id="10.14778/3551793.3551827" class="col-sm-8"> <div class="title">Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting</div> <div class="author"> Zezhi Shao, Zhao Zhang, Wei Wei<sup>*</sup>, <em>Fei Wang<sup>*</sup></em>, Yongjun Xu, Xin Cao, and Christian S. Jensen </div> <div class="periodical"> <em>Proc. VLDB Endow.</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">The 3rd-Most Cited paper in VLDB 2022</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.14778/3551793.3551827" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2022_VLDB_D2STGNN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/GestaltCogTeam/D2STGNN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:D_sINldO8mEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-378-4285F4?logo=googlescholar&amp;labelColor=beige" alt="378 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p><strong>The 3rd-Most Cited paper in VLDB 2022</strong> 2022 <em>3/357</em></p> </div> <div class="abstract hidden"> <p>We all depend on mobility, and vehicular transportation affects the daily lives of most of us. Thus, the ability to forecast the state of traffic in a road network is an important functionality and a challenging task. Traffic data is often obtained from sensors deployed in a road network. Recent proposals on spatial-temporal graph neural networks have achieved great progress at modeling complex spatial-temporal correlations in traffic data, by modeling traffic data as a diffusion process. However, intuitively, traffic data encompasses two different kinds of hidden time series signals, namely the diffusion signals and inherent signals. Unfortunately, nearly all previous works coarsely consider traffic signals entirely as the outcome of the diffusion, while neglecting the inherent signals, which impacts model performance negatively. To improve modeling performance, we propose a novel Decoupled Spatial-Temporal Framework (DSTF) that separates the diffusion and inherent traffic information in a data-driven manner, which encompasses a unique estimation gate and a residual decomposition mechanism. The separated signals can be handled subsequently by the diffusion and inherent modules separately. Further, we propose an instantiation of DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network (D2STGNN), that captures spatial-temporal correlations and also features a dynamic graph learning module that targets the learning of the dynamic characteristics of traffic networks. Extensive experiments with four real-world traffic datasets demonstrate that the framework is capable of advancing the state-of-the-art.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.14778/3551793.3551827</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Zezhi and Zhang, Zhao and Wei, Wei and Wang, Fei and Xu, Yongjun and Cao, Xin and Jensen, Christian S.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{VLDB Endowment}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2150-8097}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.14778/3551793.3551827}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.14778/3551793.3551827}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. VLDB Endow.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2733-2746}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">KDD</abbr> </div> <div id="10.1145/3534678.3539396" class="col-sm-8"> <div class="title">Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting</div> <div class="author"> Zezhi Shao, Zhao Zhang, <em>Fei Wang<sup>*</sup></em>, and Yongjun Xu </div> <div class="periodical"> <em>In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, Washington DC, USA, Aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">The 3rd-Most Cited paper in KDD 2022</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3534678.3539396" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2022_SIGKDD_STEP.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/GestaltCogTeam/STEP" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:HE397vMXCloC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-363-4285F4?logo=googlescholar&amp;labelColor=beige" alt="363 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p><strong>The 3rd-Most Cited paper in KDD 2022</strong> 2022 <em>3/254</em></p> </div> <div class="abstract hidden"> <p>Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3534678.3539396</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Zezhi and Zhang, Zhao and Wang, Fei and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450393850}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3534678.3539396}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3534678.3539396}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1567-1577}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{multivariate time series forecasting, pre-training model, spatial-temporal graph neural network}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Washington DC, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '22}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CIKM</abbr> </div> <div id="10.1145/3511808.3557702" class="col-sm-8"> <div class="title">Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting</div> <div class="author"> Zezhi Shao, Zhao Zhang, <em>Fei Wang<sup>*</sup></em>, Wei Wei, and Yongjun Xu </div> <div class="periodical"> <em>In Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</em>, Atlanta, GA, USA, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">The Most Cited paper in CIKM 2022</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3511808.3557702" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2022_CIKM_STID.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/GestaltCogTeam/STID" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:4TOpqqG69KYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-387-4285F4?logo=googlescholar&amp;labelColor=beige" alt="387 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p><strong>The Most Cited paper in CIKM 2022</strong> 2022 <em>1/561</em></p> </div> <div class="abstract hidden"> <p>Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods due to their state-of-the-art performance. However, recent works are becoming more sophisticated with limited performance improvements. This phenomenon motivates us to explore the critical factors of MTS forecasting and design a model that is as powerful as STGNNs, but more concise and efficient. In this paper, we identify the indistinguishability of samples in both spatial and temporal dimensions as a key bottleneck, and propose a simple yet effective baseline for MTS forecasting by attaching <u>S</u>patial and <u>T</u>emporal <u>ID</u>entity information (STID), which achieves the best performance and efficiency simultaneously based on simple Multi-Layer Perceptrons (MLPs). These results suggest that we can design efficient and effective models as long as they solve the indistinguishability of samples, without being limited to STGNNs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3511808.3557702</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Zezhi and Zhang, Zhao and Wang, Fei and Wei, Wei and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450392365}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3511808.3557702}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3511808.3557702}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 31st ACM International Conference on Information \&amp; Knowledge Management}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4454-4458}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{spatial-temporal graph neural network, multivariate time series forecasting, baseline}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Atlanta, GA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '22}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACM MM</abbr> </div> <div id="10.1145/3503161.3548092" class="col-sm-8"> <div class="title">Trajectory Prediction from Hierarchical Perspective</div> <div class="author"> Tangwen Qian, Yongjun Xu, Zhao Zhang, and <em>Fei Wang</em> </div> <div class="periodical"> <em>In Proceedings of the 30th ACM International Conference on Multimedia</em>, Lisboa, Portugal, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3503161.3548092" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:M3ejUd6NZC8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Predicting the future trajectories of multiple agents is essential for various applications in real life, such as surveillance systems, autonomous driving and social robots. The trajectory prediction task is influenced by many factors, including the individual historical trajectory, interactions between agents and fuzzy nature of an agent’s motion. While existing methods have made great progress on the topic of trajectory prediction, they treat all the information uniformly, which limits the sufficiency of using information. To this end, in this paper, we propose to regard all the information in a two-level hierarchical view. Particularly, the first-level view is the inter-trajectory view. In this level, we observe that the difficulty to predict different trajectory samples is different. We define trajectory difficulty and train the proposed model in an "easy-to-hard” schema. The second-level view is the intra-trajectory level. We find the influencing factors for a particular trajectory can be divided into two parts. The first part is global features, which keep stable within a trajectory, i.e., the expected destination. The second part is local features, which change over time, i.e., the current position. We believe that the two types of information should be handled in different ways. The hierarchical view is beneficial to take full advantage of the information in a fine-grained way. Experimental results validate the effectiveness of the proposed model.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3503161.3548092</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qian, Tangwen and Xu, Yongjun and Zhang, Zhao and Wang, Fei}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Trajectory Prediction from Hierarchical Perspective}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450392037}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3503161.3548092}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3503161.3548092}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 30th ACM International Conference on Multimedia}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6822-6830}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{hierarchical perspective, spatial-temporal modeling, trajectory prediction}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Lisboa, Portugal}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{MM '22}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IJCNN</abbr> </div> <div id="9533802" class="col-sm-8"> <div class="title">On Accurate Computation of Trajectory Similarity via Single Image Super-Resolution</div> <div class="author"> Hanlin Cao, Haina Tang<sup>*</sup>, Yulei Wu, <em>Fei Wang</em>, and Yongjun Xu </div> <div class="periodical"> <em>In 2021 International Joint Conference on Neural Networks (IJCNN)</em>, Jul 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/IJCNN52387.2021.9533802" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2021_IJCNN_Trajectory_Similarity.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:5nxA0vEk-isC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-17-4285F4?logo=googlescholar&amp;labelColor=beige" alt="17 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9533802</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cao, Hanlin and Tang, Haina and Wu, Yulei and Wang, Fei and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 International Joint Conference on Neural Networks (IJCNN)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On Accurate Computation of Trajectory Similarity via Single Image Super-Resolution}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-9}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Recurrent neural networks;Computational modeling;Superresolution;Predictive models;Nonuniform sampling;Data models;Trajectory}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IJCNN52387.2021.9533802}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICPR</abbr> </div> <div id="9412453" class="col-sm-8"> <div class="title">Trajectory-User Link with Attention Recurrent Networks</div> <div class="author"> Tao Sun, Yongjun Xu, <em>Fei Wang</em>, Lin Wu, Tangwen Qian, and Zezhi Shao </div> <div class="periodical"> <em>In 2020 25th International Conference on Pattern Recognition (ICPR)</em>, May 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ICPR48806.2021.9412453" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2021_ICPR_Trajectory_User_Link.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:roLk4NBRz8UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-17-4285F4?logo=googlescholar&amp;labelColor=beige" alt="17 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9412453</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Tao and Xu, Yongjun and Wang, Fei and Wu, Lin and Qian, Tangwen and Shao, Zezhi}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 25th International Conference on Pattern Recognition (ICPR)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Trajectory-User Link with Attention Recurrent Networks}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4589-4596}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Weight measurement;Training;Recurrent neural networks;Semantics;Graphics processing units;Trajectory;Pattern recognition}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICPR48806.2021.9412453}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="XU2021100179" class="col-sm-8"> <div class="title">Artificial intelligence: A powerful paradigm for scientific research</div> <div class="author"> Yongjun Xu, Xin Liu, Xin Cao, Changping Huang, Enke Liu, Sen Qian, Xingchen Liu, Yanjun Wu, Fengliang Dong, Cheng-Wei Qiu, and <span class="more-authors" title="click to view 38 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '38 more authors' ? 'Junjun Qiu, Keqin Hua, Wentao Su, Jian Wu, Huiyu Xu, Yong Han, Chenguang Fu, Zhigang Yin, Miao Liu, Ronald Roepman, Sabine Dietmann, Marko Virta, Fredrick Kengara, Ze Zhang, Lifu Zhang, Taolan Zhao, Ji Dai, Jialiang Yang, Liang Lan, Ming Luo, Zhaofeng Liu, Tao An, Bin Zhang, Xiao He, Shan Cong, Xiaohong Liu, Wei Zhang, James P. Lewis, James M. Tiedje, Qi Wang&lt;sup&gt;*&lt;/sup&gt;, Zhulin An&lt;sup&gt;*&lt;/sup&gt;, Fei Wang&lt;sup&gt;*&lt;/sup&gt;, Libo Zhang&lt;sup&gt;*&lt;/sup&gt;, Tao Huang&lt;sup&gt;*&lt;/sup&gt;, Chuan Lu&lt;sup&gt;*&lt;/sup&gt;, Zhipeng Cai&lt;sup&gt;*&lt;/sup&gt;, Fang Wang&lt;sup&gt;*&lt;/sup&gt;, Jiabao Zhang&lt;sup&gt;*&lt;/sup&gt;' : '38 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">38 more authors</span> </div> <div class="periodical"> <em>The Innovation</em>, Nov 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Best Paper Award</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2021.100179" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2021_Innvation_AI_Review.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:8k81kl-MbHgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-1830-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1830 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Fei Wang receveid the <strong>Best Paper Award</strong> 2024 <em>for the contribution to a comprehensive review of AI for Science</em></p> </div> <div class="abstract hidden"> <p>Artificial intelligence (AI) coupled with promising machine learning (ML) techniques well known from computer science is broadly affecting many aspects of various fields including science and technology, industry, and even our day-to-day life. The ML techniques have been developed to analyze high-throughput data with a view to obtaining useful insights, categorizing, predicting, and making evidence-based decisions in novel ways, which will promote the growth of novel applications and fuel the sustainable booming of AI. This paper undertakes a comprehensive survey on the development and application of AI in different aspects of fundamental sciences, including information science, mathematics, medical science, materials science, geoscience, life science, physics, and chemistry. The challenges that each discipline of science meets, and the potentials of AI techniques to handle these challenges, are discussed in detail. Moreover, we shed light on new research trends entailing the integration of AI into each scientific discipline. The aim of this paper is to provide a broad research guideline on fundamental sciences with potential infusion of AI, to help motivate researchers to deeply understand the state-of-the-art applications of AI-based fundamental sciences, and thereby to help promote the continuous development of these fundamental sciences.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XU2021100179</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Artificial intelligence: A powerful paradigm for scientific research}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100179}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2021.100179}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675821001041}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Yongjun and Liu, Xin and Cao, Xin and Huang, Changping and Liu, Enke and Qian, Sen and Liu, Xingchen and Wu, Yanjun and Dong, Fengliang and Qiu, Cheng-Wei and Qiu, Junjun and Hua, Keqin and Su, Wentao and Wu, Jian and Xu, Huiyu and Han, Yong and Fu, Chenguang and Yin, Zhigang and Liu, Miao and Roepman, Ronald and Dietmann, Sabine and Virta, Marko and Kengara, Fredrick and Zhang, Ze and Zhang, Lifu and Zhao, Taolan and Dai, Ji and Yang, Jialiang and Lan, Liang and Luo, Ming and Liu, Zhaofeng and An, Tao and Zhang, Bin and He, Xiao and Cong, Shan and Liu, Xiaohong and Zhang, Wei and Lewis, James P. and Tiedje, James M. and Wang, Qi and An, Zhulin and Wang, Fei and Zhang, Libo and Huang, Tao and Lu, Chuan and Cai, Zhipeng and Wang, Fang and Zhang, Jiabao}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{artificial intelligence, machine learning, deep learning, information science, mathematics, medical science, materials science, geoscience, life science, physics, chemistry}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#359469"> <div>Innovation</div> </abbr> </div> <div id="WU2020100033" class="col-sm-8"> <div class="title">Modeling the COVID-19 Outbreak in China through Multi-source Information Fusion</div> <div class="author"> Lin Wu<sup>*</sup>, Lizhe Wang, Nan Li, Tao Sun, Tangwen Qian, Yu Jiang, <em>Fei Wang<sup>*</sup></em>, and Yongjun Xu<sup>*</sup> </div> <div class="periodical"> <em>The Innovation</em>, Aug 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.xinn.2020.100033" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2020_Innvation_COVID-19_Modeling.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:YsMSGLbcyi4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-19-4285F4?logo=googlescholar&amp;labelColor=beige" alt="19 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Modeling the outbreak of a novel epidemic, such as coronavirus disease 2019 (COVID-19), is crucial for estimating its dynamics, predicting future spread and evaluating the effects of different interventions. However, there are three issues that make this modeling a challenging task: uncertainty in data, roughness in models, and complexity in programming. We addressed these issues by presenting an interactive individual-based simulator, which is capable of modeling an epidemic through multi-source information fusion.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WU2020100033</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Modeling the COVID-19 Outbreak in China through Multi-source Information Fusion}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Innovation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100033}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2666-6758}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.xinn.2020.100033}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2666675820300333}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Lin and Wang, Lizhe and Li, Nan and Sun, Tao and Qian, Tangwen and Jiang, Yu and Wang, Fei and Xu, Yongjun}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICANN</abbr> </div> <div id="10.1007/978-3-030-61616-8_42" class="col-sm-8"> <div class="title">CABIN: A Novel Cooperative Attention Based Location Prediction Network Using Internal-External Trajectory Dependencies</div> <div class="author"> Tangwen Qian, <em>Fei Wang<sup>*</sup></em>, Yongjun Xu, Yu Jiang, Tao Sun, and Yong Yu </div> <div class="periodical"> <em>In Artificial Neural Networks and Machine Learning – ICANN 2020</em>, Aug 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2020_ICANN_CABIN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:WF5omc3nYNoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-8-4285F4?logo=googlescholar&amp;labelColor=beige" alt="8 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Nowadays, large quantities of advanced locating sensors have been widely used, which makes it possible to deploy location-based service (LBS) enhanced by intelligent technologies. Location prediction, as one of the most fundamental technologies, aims to acquire possible location at next timestamp based on the moving pattern of current trajectories. High accuracy of location prediction could enrich and increase user experience of various LBSs and brings lots of benefits to service providers. Lots of state-of-the-art research try to model spatial-temporal trajectories based on recurrent neural networks (RNNs), yet fails to arrive at a practical usability. We observe that there exists two ways to improve through attention mechanism which performs well in computer vision and natural language processing domains. Firstly recent location prediction methods are usually equipped with single-head attention mechanism to promote accuracy, which is only able to capture limited information in a specific subspace at a specific position. Secondly, existing methods focus on external relations between spatial-temporal trajectories, but miss internal relations in each spatial-temporal trajectory. To tackle the problem of model spatial-temporal patterns of mobility, we propose a novel Cooperative Attention Based location prediction network using Internal-External trajectory dependencies correspondingly in this paper. We also design and perform experiments on two real-world check-in datasets, Foursquare data in New York and Tokyo cities. Evaluation results demonstrate that our method outperforms state-of-the-art models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1007/978-3-030-61616-8_42</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qian, Tangwen and Wang, Fei and Xu, Yongjun and Jiang, Yu and Sun, Tao and Yu, Yong}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Farka{\v{s}}, Igor and Masulli, Paolo and Wermter, Stefan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CABIN: A Novel Cooperative Attention Based Location Prediction Network Using Internal-External Trajectory Dependencies}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Neural Networks and Machine Learning -- ICANN 2020}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{521--532}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-61616-8}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IJCNN</abbr> </div> <div id="9206609" class="col-sm-8"> <div class="title">TULSN: Siamese Network for Trajectory-user Linking</div> <div class="author"> Yong Yu, Haina Tang<sup>*</sup>, <em>Fei Wang</em>, Lin Wu, Tangwen Qian, Tao Sun, and Yongjun Xu </div> <div class="periodical"> <em>In 2020 International Joint Conference on Neural Networks (IJCNN)</em>, Aug 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/IJCNN48605.2020.9206609" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2020_IJCNN_TULSN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:eQOLeE2rZwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-26-4285F4?logo=googlescholar&amp;labelColor=beige" alt="26 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9206609</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Yong and Tang, Haina and Wang, Fei and Wu, Lin and Qian, Tangwen and Sun, Tao and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 International Joint Conference on Neural Networks (IJCNN)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TULSN: Siamese Network for Trajectory-user Linking}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-8}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Trajectory;Semantics;Learning systems;Training;Data mining;Task analysis;Data models;Siamese Network;Spatio-temporal data;User identification}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IJCNN48605.2020.9206609}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE Network</abbr> </div> <div id="9055731" class="col-sm-8"> <div class="title">Data Security and Privacy Challenges of Computing Offloading in FINs</div> <div class="author"> <em>Fei Wang<sup>*</sup></em>, Boyu Diao, Tao Sun, and Yongjun Xu </div> <div class="periodical"> <em>IEEE Network</em>, Apr 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/MNET.001.1900140" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2020_IEEE_Network.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:W7OEmFMy1HYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-22-4285F4?logo=googlescholar&amp;labelColor=beige" alt="22 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9055731</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Fei and Diao, Boyu and Sun, Tao and Xu, Yongjun}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Network}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Data Security and Privacy Challenges of Computing Offloading in FINs}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{14-20}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Task analysis;Cloud computing;Data privacy;Edge computing;Smart homes;Data security}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MNET.001.1900140}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Navigation</abbr> </div> <div id="Wu_Xu_Wang_Wang_Xu_2017" class="col-sm-8"> <div class="title">Mapping Global Shipping Density from AIS Data</div> <div class="author"> Lin Wu, Yongjun Xu, Qi Wang, <em>Fei Wang</em>, and Zhiwei Xu </div> <div class="periodical"> <em>Journal of Navigation</em>, Apr 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1017/S0373463316000345" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2016_Navigation.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:ufrVoPGSRksC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-226-4285F4?logo=googlescholar&amp;labelColor=beige" alt="226 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Wu_Xu_Wang_Wang_Xu_2017</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mapping Global Shipping Density from AIS Data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{70}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1017/S0373463316000345}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Navigation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Lin and Xu, Yongjun and Wang, Qi and Wang, Fei and Xu, Zhiwei}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{67-81}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE TVT</abbr> </div> <div id="7038220" class="col-sm-8"> <div class="title">2FLIP: A Two-Factor Lightweight Privacy-Preserving Authentication Scheme for VANET</div> <div class="author"> <em>Fei Wang</em>, Yongjun Xu, Hanwen Zhang, Yujun Zhang, and Liehuang Zhu </div> <div class="periodical"> <em>IEEE Transactions on Vehicular Technology</em>, Feb 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TVT.2015.2402166" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/2016_IEEE_TVT.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MuEc_JEAAAAJ&amp;citation_for_view=MuEc_JEAAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/Cited-251-4285F4?logo=googlescholar&amp;labelColor=beige" alt="251 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">7038220</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Fei and Xu, Yongjun and Zhang, Hanwen and Zhang, Yujun and Zhu, Liehuang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Vehicular Technology}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{2FLIP: A Two-Factor Lightweight Privacy-Preserving Authentication Scheme for VANET}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{65}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{896-911}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Vehicles;Privacy;Vehicular ad hoc networks;Authentication;Telematics;Biology;Privacy;vehicular ad hoc network;two factor authentication;conditional traceability;strong non-repudiation;Conditional traceability;privacy;strong nonrepudiation;two-factor authentication;vehicular ad-hoc network (VANET)}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TVT.2015.2402166}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Fei Wang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>